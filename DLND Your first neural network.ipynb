{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your first neural network\n",
    "\n",
    "In this project, you'll build your first neural network and use it to predict daily bike rental ridership. We've provided some of the code, but left the implementation of the neural network up to you (for the most part). After you've submitted this project, feel free to explore the data and the model more.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare the data\n",
    "\n",
    "A critical step in working with neural networks is preparing the data correctly. Variables on different scales make it difficult for the network to efficiently learn the correct weights. Below, we've written the code to load and prepare the data. You'll learn more about this soon!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'Bike-Sharing-Dataset/hour.csv'\n",
    "\n",
    "rides = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
       "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
       "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
       "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
       "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
       "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
       "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
       "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
       "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
       "4           1  0.24  0.2879  0.75        0.0       0           1    1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rides.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking out the data\n",
    "\n",
    "This dataset has the number of riders for each hour of each day from January 1 2011 to December 31 2012. The number of riders is split between casual and registered, summed up in the `cnt` column. You can see the first few rows of the data above.\n",
    "\n",
    "Below is a plot showing the number of bike riders over the first 10 days or so in the data set. (Some days don't have exactly 24 entries in the data set, so it's not exactly 10 days.) You can see the hourly rentals here. This data is pretty complicated! The weekends have lower over all ridership and there are spikes when people are biking to and from work during the week. Looking at the data above, we also have information about temperature, humidity, and windspeed, all of these likely affecting the number of riders. You'll be trying to capture all this with your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rides[:24*10].plot(x='dteday', y='cnt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy variables\n",
    "Here we have some categorical variables like season, weather, month. To include these in our model, we'll need to make binary dummy variables. This is simple to do with Pandas thanks to `get_dummies()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "      <th>season_1</th>\n",
       "      <th>season_2</th>\n",
       "      <th>...</th>\n",
       "      <th>hr_21</th>\n",
       "      <th>hr_22</th>\n",
       "      <th>hr_23</th>\n",
       "      <th>weekday_0</th>\n",
       "      <th>weekday_1</th>\n",
       "      <th>weekday_2</th>\n",
       "      <th>weekday_3</th>\n",
       "      <th>weekday_4</th>\n",
       "      <th>weekday_5</th>\n",
       "      <th>weekday_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   yr  holiday  temp   hum  windspeed  casual  registered  cnt  season_1  \\\n",
       "0   0        0  0.24  0.81        0.0       3          13   16         1   \n",
       "1   0        0  0.22  0.80        0.0       8          32   40         1   \n",
       "2   0        0  0.22  0.80        0.0       5          27   32         1   \n",
       "3   0        0  0.24  0.75        0.0       3          10   13         1   \n",
       "4   0        0  0.24  0.75        0.0       0           1    1         1   \n",
       "\n",
       "   season_2    ...      hr_21  hr_22  hr_23  weekday_0  weekday_1  weekday_2  \\\n",
       "0         0    ...          0      0      0          0          0          0   \n",
       "1         0    ...          0      0      0          0          0          0   \n",
       "2         0    ...          0      0      0          0          0          0   \n",
       "3         0    ...          0      0      0          0          0          0   \n",
       "4         0    ...          0      0      0          0          0          0   \n",
       "\n",
       "   weekday_3  weekday_4  weekday_5  weekday_6  \n",
       "0          0          0          0          1  \n",
       "1          0          0          0          1  \n",
       "2          0          0          0          1  \n",
       "3          0          0          0          1  \n",
       "4          0          0          0          1  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_fields = ['season', 'weathersit', 'mnth', 'hr', 'weekday']\n",
    "for each in dummy_fields:\n",
    "    dummies = pd.get_dummies(rides[each], prefix=each, drop_first=False)\n",
    "    rides = pd.concat([rides, dummies], axis=1)\n",
    "\n",
    "fields_to_drop = ['instant', 'dteday', 'season', 'weathersit', \n",
    "                  'weekday', 'atemp', 'mnth', 'workingday', 'hr']\n",
    "data = rides.drop(fields_to_drop, axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling target variables\n",
    "To make training the network easier, we'll standardize each of the continuous variables. That is, we'll shift and scale the variables such that they have zero mean and a standard deviation of 1.\n",
    "\n",
    "The scaling factors are saved so we can go backwards when we use the network for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quant_features = ['casual', 'registered', 'cnt', 'temp', 'hum', 'windspeed']\n",
    "# Store scalings in a dictionary so we can convert back later\n",
    "scaled_features = {}\n",
    "for each in quant_features:\n",
    "    mean, std = data[each].mean(), data[each].std()\n",
    "    scaled_features[each] = [mean, std]\n",
    "    data.loc[:, each] = (data[each] - mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into training, testing, and validation sets\n",
    "\n",
    "We'll save the data for the last approximately 21 days to use as a test set after we've trained the network. We'll use this set to make predictions and compare them with the actual number of riders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save data for approximately the last 21 days \n",
    "test_data = data[-21*24:]\n",
    "\n",
    "# Now remove the test data from the data set \n",
    "data = data[:-21*24]\n",
    "\n",
    "# Separate the data into features and targets\n",
    "target_fields = ['cnt', 'casual', 'registered']\n",
    "features, targets = data.drop(target_fields, axis=1), data[target_fields]\n",
    "test_features, test_targets = test_data.drop(target_fields, axis=1), test_data[target_fields]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll split the data into two sets, one for training and one for validating as the network is being trained. Since this is time series data, we'll train on historical data, then try to predict on future data (the validation set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hold out the last 60 days or so of the remaining data as a validation set\n",
    "train_features, train_targets = features[:-60*24], targets[:-60*24]\n",
    "val_features, val_targets = features[-60*24:], targets[-60*24:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to build the network\n",
    "\n",
    "Below you'll build your network. We've built out the structure and the backwards pass. You'll implement the forward pass through the network. You'll also set the hyperparameters: the learning rate, the number of hidden units, and the number of training passes.\n",
    "\n",
    "The network has two layers, a hidden layer and an output layer. The hidden layer will use the sigmoid function for activations. The output layer has only one node and is used for the regression, the output of the node is the same as the input of the node. That is, the activation function is $f(x)=x$. A function that takes the input signal and generates an output signal, but takes into account the threshold, is called an activation function. We work through each layer of our network calculating the outputs for each neuron. All of the outputs from one layer become inputs to the neurons on the next layer. This process is called *forward propagation*.\n",
    "\n",
    "We use the weights to propagate signals forward from the input to the output layers in a neural network. We use the weights to also propagate error backwards from the output back into the network to update our weights. This is called *backpropagation*.\n",
    "\n",
    "> **Hint:** You'll need the derivative of the output activation function ($f(x) = x$) for the backpropagation implementation. If you aren't familiar with calculus, this function is equivalent to the equation $y = x$. What is the slope of that equation? That is the derivative of $f(x)$.\n",
    "\n",
    "Below, you have these tasks:\n",
    "1. Implement the sigmoid function to use as the activation function. Set `self.activation_function` in `__init__` to your sigmoid function.\n",
    "2. Implement the forward pass in the `train` method.\n",
    "3. Implement the backpropagation algorithm in the `train` method, including calculating the output error.\n",
    "4. Implement the forward pass in the `run` method.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # Set number of nodes in input, hidden and output layers.\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        # Initialize weights\n",
    "        self.weights_input_to_hidden = np.random.normal(0.0, self.hidden_nodes**-0.5, \n",
    "                                       (self.hidden_nodes, self.input_nodes))\n",
    "\n",
    "        self.weights_hidden_to_output = np.random.normal(0.0, self.output_nodes**-0.5, \n",
    "                                       (self.output_nodes, self.hidden_nodes))\n",
    "        self.lr = learning_rate\n",
    "        \n",
    "        #### TODO: Set self.activation_function to your implemented sigmoid function ####\n",
    "        #\n",
    "        # Note: in Python, you can define a function with a lambda expression,\n",
    "        # as shown below.\n",
    "        \n",
    "            \n",
    "        \n",
    "        # Replace 0 with your sigmoid calculation.\n",
    "        \n",
    "        ### If the lambda code above is not something you're familiar with,\n",
    "        # You can uncomment out the following three lines and put your \n",
    "        # implementation there instead.\n",
    "        #\n",
    "        def sigmoid(x):\n",
    "            return 1/(1+ np.exp(-x))  # Replace 0 with your sigmoid calculation here\n",
    "        self.activation_function = sigmoid\n",
    "                    \n",
    "    \n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # Convert inputs list to 2d array\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        targets = np.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        #### Implement the forward pass here ####\n",
    "        ### Forward pass ###\n",
    "        # TODO: Hidden layer - Replace these values with your calculations.\n",
    "        hidden_inputs = np.dot(self.weights_input_to_hidden,inputs) # signals into hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs) # signals from hidden layer\n",
    "        \n",
    "        # TODO: Output layer - Replace these values with your calculations.\n",
    "        final_inputs = np.dot(self.weights_hidden_to_output,hidden_outputs)\n",
    "        final_outputs = final_inputs # signals from final output layer\n",
    "        \n",
    "        #### Implement the backward pass here ####\n",
    "        ### Backward pass ###\n",
    "        \n",
    "        # TODO: Output error - Replace this value with your calculations.\n",
    "        output_errors = (targets - final_outputs)  # Output layer error is the difference between desired target and actual output.\n",
    "      \n",
    "        # TODO: Backpropagated error - Replace these values with your calculations.\n",
    "        hidden_errors = np.dot(self.weights_hidden_to_output.T , output_errors) # errors propagated to the hidden layer\n",
    "        hidden_grad =  hidden_outputs * (1-hidden_outputs) # hidden layer gradients\n",
    "        \n",
    "        # TODO: Update the weights - Replace these values with your calculations.\n",
    "        self.weights_hidden_to_output +=   self.lr* np.dot(output_errors, hidden_outputs.T)# update hidden-to-output weights with gradient descent step\n",
    "        self.weights_input_to_hidden += self.lr* np.dot(hidden_errors*hidden_grad, inputs.T)\n",
    "        # update input-to-hidden weights with gradient descent step\n",
    " \n",
    "        \n",
    "    def run(self, inputs_list):\n",
    "           # Run a forward pass through the network\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        #### Implement the forward pass here ####\n",
    "        # TODO: Hidden layer - replace these values with the appropriate calculations.\n",
    "        hidden_inputs = np.dot(self.weights_input_to_hidden, inputs)# signals into hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs) # signals from hidden layer\n",
    "        \n",
    "        # TODO: Output layer - Replace these values with the appropriate calculations.\n",
    "        final_inputs = np.dot(self.weights_hidden_to_output, hidden_outputs)\n",
    "        final_outputs = final_inputs # signals from final output layer \n",
    "        print(inputs)\n",
    "        return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MSE(y, Y):\n",
    "    return np.mean((y-Y)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network\n",
    "\n",
    "Here you'll set the hyperparameters for the network. The strategy here is to find hyperparameters such that the error on the training set is low, but you're not overfitting to the data. If you train the network too long or have too many hidden nodes, it can become overly specific to the training set and will fail to generalize to the validation set. That is, the loss on the validation set will start increasing as the training set loss drops.\n",
    "\n",
    "You'll also be using a method know as Stochastic Gradient Descent (SGD) to train the network. The idea is that for each training pass, you grab a random sample of the data instead of using the whole data set. You use many more training passes than with normal gradient descent, but each pass is much faster. This ends up training the network more efficiently. You'll learn more about SGD later.\n",
    "\n",
    "### Choose the number of epochs\n",
    "This is the number of times the dataset will pass through the network, each time updating the weights. As the number of epochs increases, the network becomes better and better at predicting the targets in the training set. You'll need to choose enough epochs to train the network well but not too many or you'll be overfitting.\n",
    "\n",
    "### Choose the learning rate\n",
    "This scales the size of weight updates. If this is too big, the weights tend to explode and the network fails to fit the data. A good choice to start at is 0.1. If the network has problems fitting the data, try reducing the learning rate. Note that the lower the learning rate, the smaller the steps are in the weight updates and the longer it takes for the neural network to converge.\n",
    "\n",
    "### Choose the number of hidden nodes\n",
    "The more hidden nodes you have, the more accurate predictions the model will make. Try a few different numbers and see how it affects the performance. You can look at the losses dictionary for a metric of the network performance. If the number of hidden units is too low, then the model won't have enough space to learn and if it is too high there are too many options for the direction that the learning can take. The trick here is to find the right balance in number of hidden units you choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 0.0% ... Training loss: 1.766 ... Validation loss: 1.020[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 0.06% ... Training loss: 0.677 ... Validation loss: 0.951[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 0.13% ... Training loss: 0.836 ... Validation loss: 0.928[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 0.2% ... Training loss: 0.485 ... Validation loss: 0.852[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 0.26% ... Training loss: 0.659 ... Validation loss: 1.042[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 0.33% ... Training loss: 0.460 ... Validation loss: 0.599[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 0.4% ... Training loss: 0.570 ... Validation loss: 0.651[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0.46% ... Training loss: 0.452 ... Validation loss: 0.721[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 0.53% ... Training loss: 0.440 ... Validation loss: 0.760[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 0.6% ... Training loss: 0.418 ... Validation loss: 0.659[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 0.66% ... Training loss: 0.445 ... Validation loss: 0.497[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 0.73% ... Training loss: 0.382 ... Validation loss: 0.523[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 0.8% ... Training loss: 0.333 ... Validation loss: 0.499[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 0.86% ... Training loss: 0.370 ... Validation loss: 0.491[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 0.93% ... Training loss: 0.344 ... Validation loss: 0.486[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 1.0% ... Training loss: 0.389 ... Validation loss: 0.580[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 1.06% ... Training loss: 0.369 ... Validation loss: 0.527[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 1.13% ... Training loss: 0.327 ... Validation loss: 0.475[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 1.2% ... Training loss: 0.298 ... Validation loss: 0.463[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 1.26% ... Training loss: 0.315 ... Validation loss: 0.446[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 1.33% ... Training loss: 0.301 ... Validation loss: 0.504[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 1.4% ... Training loss: 0.312 ... Validation loss: 0.494[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 1.46% ... Training loss: 0.283 ... Validation loss: 0.497[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 1.53% ... Training loss: 0.260 ... Validation loss: 0.533[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 1.6% ... Training loss: 0.362 ... Validation loss: 0.612[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 1.66% ... Training loss: 0.293 ... Validation loss: 0.531[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 1.73% ... Training loss: 0.256 ... Validation loss: 0.482[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 1.8% ... Training loss: 0.274 ... Validation loss: 0.458[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 1.86% ... Training loss: 0.249 ... Validation loss: 0.455[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 1.93% ... Training loss: 0.327 ... Validation loss: 0.446[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 2.0% ... Training loss: 0.226 ... Validation loss: 0.395[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 2.06% ... Training loss: 0.294 ... Validation loss: 0.448[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 2.13% ... Training loss: 0.286 ... Validation loss: 0.456[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 2.2% ... Training loss: 0.241 ... Validation loss: 0.397[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 2.26% ... Training loss: 0.257 ... Validation loss: 0.409[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 2.33% ... Training loss: 0.330 ... Validation loss: 0.515[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 2.4% ... Training loss: 0.200 ... Validation loss: 0.380[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 2.46% ... Training loss: 0.303 ... Validation loss: 0.454[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 2.53% ... Training loss: 0.213 ... Validation loss: 0.292[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 2.6% ... Training loss: 0.299 ... Validation loss: 0.389[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 2.66% ... Training loss: 0.218 ... Validation loss: 0.367[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 2.73% ... Training loss: 0.185 ... Validation loss: 0.344[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 2.8% ... Training loss: 0.208 ... Validation loss: 0.381[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 2.86% ... Training loss: 0.224 ... Validation loss: 0.352[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 2.93% ... Training loss: 0.217 ... Validation loss: 0.411[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 3.0% ... Training loss: 0.193 ... Validation loss: 0.334[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 3.06% ... Training loss: 0.409 ... Validation loss: 0.507[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 3.13% ... Training loss: 0.240 ... Validation loss: 0.366[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 3.2% ... Training loss: 0.199 ... Validation loss: 0.316[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 3.26% ... Training loss: 0.223 ... Validation loss: 0.324[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 3.33% ... Training loss: 0.196 ... Validation loss: 0.333[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 3.4% ... Training loss: 0.233 ... Validation loss: 0.396[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 3.46% ... Training loss: 0.275 ... Validation loss: 0.423[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 3.53% ... Training loss: 0.265 ... Validation loss: 0.408[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 3.6% ... Training loss: 0.176 ... Validation loss: 0.287[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 3.66% ... Training loss: 0.176 ... Validation loss: 0.302[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 3.73% ... Training loss: 0.188 ... Validation loss: 0.561[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 3.8% ... Training loss: 0.173 ... Validation loss: 0.323[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 3.86% ... Training loss: 0.172 ... Validation loss: 0.354[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 3.93% ... Training loss: 0.201 ... Validation loss: 0.379[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 4.0% ... Training loss: 0.158 ... Validation loss: 0.272[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 4.06% ... Training loss: 0.169 ... Validation loss: 0.330[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 4.13% ... Training loss: 0.159 ... Validation loss: 0.308[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 4.2% ... Training loss: 0.176 ... Validation loss: 0.283[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 4.26% ... Training loss: 0.169 ... Validation loss: 0.317[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 4.33% ... Training loss: 0.171 ... Validation loss: 0.288[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 4.4% ... Training loss: 0.212 ... Validation loss: 0.300[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 4.46% ... Training loss: 0.174 ... Validation loss: 0.322[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 4.53% ... Training loss: 0.213 ... Validation loss: 0.341[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 4.6% ... Training loss: 0.158 ... Validation loss: 0.261[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 4.66% ... Training loss: 0.218 ... Validation loss: 0.268[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 4.73% ... Training loss: 0.157 ... Validation loss: 0.244[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 4.8% ... Training loss: 0.166 ... Validation loss: 0.238[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 4.86% ... Training loss: 0.167 ... Validation loss: 0.295[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 4.93% ... Training loss: 0.173 ... Validation loss: 0.294[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 5.0% ... Training loss: 0.157 ... Validation loss: 0.240[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 5.06% ... Training loss: 0.137 ... Validation loss: 0.254[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 5.13% ... Training loss: 0.137 ... Validation loss: 0.232[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 5.2% ... Training loss: 0.165 ... Validation loss: 0.305[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 5.26% ... Training loss: 0.146 ... Validation loss: 0.269[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 5.33% ... Training loss: 0.166 ... Validation loss: 0.259[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 5.4% ... Training loss: 0.186 ... Validation loss: 0.311[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 5.46% ... Training loss: 0.137 ... Validation loss: 0.257[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 5.53% ... Training loss: 0.142 ... Validation loss: 0.210[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 5.6% ... Training loss: 0.128 ... Validation loss: 0.198[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 5.66% ... Training loss: 0.128 ... Validation loss: 0.200[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 5.73% ... Training loss: 0.145 ... Validation loss: 0.203[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 5.8% ... Training loss: 0.165 ... Validation loss: 0.219[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 5.86% ... Training loss: 0.116 ... Validation loss: 0.219[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 5.93% ... Training loss: 0.119 ... Validation loss: 0.203[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 6.0% ... Training loss: 0.143 ... Validation loss: 0.228[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 6.06% ... Training loss: 0.131 ... Validation loss: 0.242[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 6.13% ... Training loss: 0.126 ... Validation loss: 0.224[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 6.2% ... Training loss: 0.150 ... Validation loss: 0.247[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 6.26% ... Training loss: 0.109 ... Validation loss: 0.203[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 6.33% ... Training loss: 0.206 ... Validation loss: 0.406[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 6.4% ... Training loss: 0.108 ... Validation loss: 0.234[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 6.46% ... Training loss: 0.109 ... Validation loss: 0.208[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 6.53% ... Training loss: 0.112 ... Validation loss: 0.211[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 6.6% ... Training loss: 0.118 ... Validation loss: 0.204[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 6.66% ... Training loss: 0.147 ... Validation loss: 0.228[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 6.73% ... Training loss: 0.126 ... Validation loss: 0.238[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 6.8% ... Training loss: 0.110 ... Validation loss: 0.200[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 6.86% ... Training loss: 0.110 ... Validation loss: 0.201[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 6.93% ... Training loss: 0.111 ... Validation loss: 0.185[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 7.0% ... Training loss: 0.122 ... Validation loss: 0.228[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 7.06% ... Training loss: 0.144 ... Validation loss: 0.269[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 7.13% ... Training loss: 0.112 ... Validation loss: 0.235[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 7.2% ... Training loss: 0.167 ... Validation loss: 0.259[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 7.26% ... Training loss: 0.144 ... Validation loss: 0.243[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 7.33% ... Training loss: 0.205 ... Validation loss: 0.245[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 7.4% ... Training loss: 0.165 ... Validation loss: 0.297[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 7.46% ... Training loss: 0.145 ... Validation loss: 0.251[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 7.53% ... Training loss: 0.134 ... Validation loss: 0.268[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 7.6% ... Training loss: 0.152 ... Validation loss: 0.307[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 7.66% ... Training loss: 0.131 ... Validation loss: 0.253[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 7.73% ... Training loss: 0.118 ... Validation loss: 0.227[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 7.8% ... Training loss: 0.130 ... Validation loss: 0.202[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 7.86% ... Training loss: 0.119 ... Validation loss: 0.242[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 7.93% ... Training loss: 0.112 ... Validation loss: 0.237[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 8.0% ... Training loss: 0.152 ... Validation loss: 0.312[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 8.06% ... Training loss: 0.144 ... Validation loss: 0.259[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 8.13% ... Training loss: 0.129 ... Validation loss: 0.235[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 8.2% ... Training loss: 0.116 ... Validation loss: 0.220[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 8.26% ... Training loss: 0.145 ... Validation loss: 0.224[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 8.33% ... Training loss: 0.114 ... Validation loss: 0.211[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 8.4% ... Training loss: 0.161 ... Validation loss: 0.232[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 8.46% ... Training loss: 0.155 ... Validation loss: 0.253[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 8.53% ... Training loss: 0.108 ... Validation loss: 0.178[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 8.6% ... Training loss: 0.101 ... Validation loss: 0.182[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 8.66% ... Training loss: 0.185 ... Validation loss: 0.319[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 8.73% ... Training loss: 0.113 ... Validation loss: 0.219[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 8.8% ... Training loss: 0.095 ... Validation loss: 0.209[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 8.86% ... Training loss: 0.089 ... Validation loss: 0.191[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 8.93% ... Training loss: 0.109 ... Validation loss: 0.248[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 9.0% ... Training loss: 0.112 ... Validation loss: 0.207[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 9.06% ... Training loss: 0.119 ... Validation loss: 0.217[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 9.13% ... Training loss: 0.111 ... Validation loss: 0.214[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 9.2% ... Training loss: 0.125 ... Validation loss: 0.218[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 9.26% ... Training loss: 0.105 ... Validation loss: 0.180[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 9.33% ... Training loss: 0.096 ... Validation loss: 0.192[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 9.4% ... Training loss: 0.099 ... Validation loss: 0.195[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 9.46% ... Training loss: 0.113 ... Validation loss: 0.179[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 9.53% ... Training loss: 0.120 ... Validation loss: 0.205[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 9.6% ... Training loss: 0.106 ... Validation loss: 0.183[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 9.66% ... Training loss: 0.108 ... Validation loss: 0.195[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 9.73% ... Training loss: 0.120 ... Validation loss: 0.205[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 9.8% ... Training loss: 0.112 ... Validation loss: 0.200[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 9.86% ... Training loss: 0.126 ... Validation loss: 0.200[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 9.93% ... Training loss: 0.122 ... Validation loss: 0.201[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 10.0% ... Training loss: 0.126 ... Validation loss: 0.252[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 10.0% ... Training loss: 0.104 ... Validation loss: 0.189[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 10.1% ... Training loss: 0.186 ... Validation loss: 0.305[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 10.2% ... Training loss: 0.102 ... Validation loss: 0.178[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 10.2% ... Training loss: 0.105 ... Validation loss: 0.173[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 10.3% ... Training loss: 0.114 ... Validation loss: 0.188[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 10.4% ... Training loss: 0.095 ... Validation loss: 0.176[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 10.4% ... Training loss: 0.120 ... Validation loss: 0.214[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 10.5% ... Training loss: 0.109 ... Validation loss: 0.191[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 10.6% ... Training loss: 0.111 ... Validation loss: 0.174[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 10.6% ... Training loss: 0.093 ... Validation loss: 0.169[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 10.7% ... Training loss: 0.109 ... Validation loss: 0.246[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 10.8% ... Training loss: 0.106 ... Validation loss: 0.218[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 10.8% ... Training loss: 0.110 ... Validation loss: 0.191[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 10.9% ... Training loss: 0.112 ... Validation loss: 0.182[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 11.0% ... Training loss: 0.087 ... Validation loss: 0.170[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 11.0% ... Training loss: 0.087 ... Validation loss: 0.183[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 11.1% ... Training loss: 0.112 ... Validation loss: 0.187[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 11.2% ... Training loss: 0.117 ... Validation loss: 0.190[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 11.2% ... Training loss: 0.126 ... Validation loss: 0.192[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 11.3% ... Training loss: 0.133 ... Validation loss: 0.234[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 11.4% ... Training loss: 0.087 ... Validation loss: 0.179[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 11.4% ... Training loss: 0.097 ... Validation loss: 0.177[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 11.5% ... Training loss: 0.110 ... Validation loss: 0.190[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 11.6% ... Training loss: 0.100 ... Validation loss: 0.188[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 11.6% ... Training loss: 0.087 ... Validation loss: 0.184[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 11.7% ... Training loss: 0.248 ... Validation loss: 0.224[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 11.8% ... Training loss: 0.137 ... Validation loss: 0.239[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 11.8% ... Training loss: 0.128 ... Validation loss: 0.221[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 11.9% ... Training loss: 0.149 ... Validation loss: 0.231[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 12.0% ... Training loss: 0.099 ... Validation loss: 0.197[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 12.0% ... Training loss: 0.123 ... Validation loss: 0.236[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 12.1% ... Training loss: 0.099 ... Validation loss: 0.164[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 12.2% ... Training loss: 0.097 ... Validation loss: 0.177[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 12.2% ... Training loss: 0.146 ... Validation loss: 0.247[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 12.3% ... Training loss: 0.101 ... Validation loss: 0.169[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 12.4% ... Training loss: 0.089 ... Validation loss: 0.169[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 12.4% ... Training loss: 0.102 ... Validation loss: 0.215[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 12.5% ... Training loss: 0.107 ... Validation loss: 0.190[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 12.6% ... Training loss: 0.094 ... Validation loss: 0.207[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 12.6% ... Training loss: 0.098 ... Validation loss: 0.194[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 12.7% ... Training loss: 0.139 ... Validation loss: 0.196[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 12.8% ... Training loss: 0.093 ... Validation loss: 0.165[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 12.8% ... Training loss: 0.095 ... Validation loss: 0.177[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 12.9% ... Training loss: 0.080 ... Validation loss: 0.169[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 13.0% ... Training loss: 0.152 ... Validation loss: 0.281[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 13.0% ... Training loss: 0.093 ... Validation loss: 0.165[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 13.1% ... Training loss: 0.098 ... Validation loss: 0.237[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 13.2% ... Training loss: 0.085 ... Validation loss: 0.183[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 13.2% ... Training loss: 0.091 ... Validation loss: 0.202[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 13.3% ... Training loss: 0.089 ... Validation loss: 0.177[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 13.4% ... Training loss: 0.108 ... Validation loss: 0.190[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 13.4% ... Training loss: 0.107 ... Validation loss: 0.210[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 13.5% ... Training loss: 0.095 ... Validation loss: 0.197[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 13.6% ... Training loss: 0.090 ... Validation loss: 0.176[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 13.6% ... Training loss: 0.102 ... Validation loss: 0.183[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 13.7% ... Training loss: 0.099 ... Validation loss: 0.185[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 13.8% ... Training loss: 0.166 ... Validation loss: 0.240[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 13.8% ... Training loss: 0.090 ... Validation loss: 0.192[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 13.9% ... Training loss: 0.119 ... Validation loss: 0.224[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 14.0% ... Training loss: 0.152 ... Validation loss: 0.266[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 14.0% ... Training loss: 0.130 ... Validation loss: 0.263[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 14.1% ... Training loss: 0.108 ... Validation loss: 0.170[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 14.2% ... Training loss: 0.219 ... Validation loss: 0.209[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 14.2% ... Training loss: 0.091 ... Validation loss: 0.162[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 14.3% ... Training loss: 0.094 ... Validation loss: 0.158[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 14.4% ... Training loss: 0.084 ... Validation loss: 0.161[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 14.4% ... Training loss: 0.099 ... Validation loss: 0.191[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 14.5% ... Training loss: 0.112 ... Validation loss: 0.181[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 14.6% ... Training loss: 0.121 ... Validation loss: 0.158[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 14.6% ... Training loss: 0.107 ... Validation loss: 0.171[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 14.7% ... Training loss: 0.135 ... Validation loss: 0.188[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 14.8% ... Training loss: 0.099 ... Validation loss: 0.155[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 14.8% ... Training loss: 0.094 ... Validation loss: 0.166[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 14.9% ... Training loss: 0.086 ... Validation loss: 0.163[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 15.0% ... Training loss: 0.095 ... Validation loss: 0.167[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 15.0% ... Training loss: 0.088 ... Validation loss: 0.160[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 15.1% ... Training loss: 0.100 ... Validation loss: 0.181[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 15.2% ... Training loss: 0.101 ... Validation loss: 0.196[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 15.2% ... Training loss: 0.097 ... Validation loss: 0.157[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 15.3% ... Training loss: 0.103 ... Validation loss: 0.213[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 15.4% ... Training loss: 0.090 ... Validation loss: 0.174[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 15.4% ... Training loss: 0.100 ... Validation loss: 0.196[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 15.5% ... Training loss: 0.105 ... Validation loss: 0.178[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 15.6% ... Training loss: 0.103 ... Validation loss: 0.183[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 15.6% ... Training loss: 0.099 ... Validation loss: 0.187[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 15.7% ... Training loss: 0.105 ... Validation loss: 0.187[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 15.8% ... Training loss: 0.125 ... Validation loss: 0.214[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 15.8% ... Training loss: 0.098 ... Validation loss: 0.200[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 15.9% ... Training loss: 0.105 ... Validation loss: 0.202[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 16.0% ... Training loss: 0.099 ... Validation loss: 0.211[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 16.0% ... Training loss: 0.105 ... Validation loss: 0.192[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 16.1% ... Training loss: 0.091 ... Validation loss: 0.192[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 16.2% ... Training loss: 0.096 ... Validation loss: 0.222[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 16.2% ... Training loss: 0.114 ... Validation loss: 0.197[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 16.3% ... Training loss: 0.087 ... Validation loss: 0.191[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 16.4% ... Training loss: 0.077 ... Validation loss: 0.175[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 16.4% ... Training loss: 0.088 ... Validation loss: 0.176[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 16.5% ... Training loss: 0.101 ... Validation loss: 0.162[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 16.6% ... Training loss: 0.091 ... Validation loss: 0.174[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 16.6% ... Training loss: 0.083 ... Validation loss: 0.171[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 16.7% ... Training loss: 0.112 ... Validation loss: 0.251[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 16.8% ... Training loss: 0.102 ... Validation loss: 0.181[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 16.8% ... Training loss: 0.093 ... Validation loss: 0.179[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 16.9% ... Training loss: 0.106 ... Validation loss: 0.198[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 17.0% ... Training loss: 0.083 ... Validation loss: 0.172[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 17.0% ... Training loss: 0.173 ... Validation loss: 0.275[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 17.1% ... Training loss: 0.108 ... Validation loss: 0.223[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 17.2% ... Training loss: 0.078 ... Validation loss: 0.186[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 17.2% ... Training loss: 0.159 ... Validation loss: 0.209[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 17.3% ... Training loss: 0.153 ... Validation loss: 0.235[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 17.4% ... Training loss: 0.092 ... Validation loss: 0.175[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 17.4% ... Training loss: 0.117 ... Validation loss: 0.242[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 17.5% ... Training loss: 0.091 ... Validation loss: 0.170[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 17.6% ... Training loss: 0.090 ... Validation loss: 0.209[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 17.6% ... Training loss: 0.101 ... Validation loss: 0.197[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 17.7% ... Training loss: 0.104 ... Validation loss: 0.208[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 17.8% ... Training loss: 0.099 ... Validation loss: 0.232[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 17.8% ... Training loss: 0.103 ... Validation loss: 0.220[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 17.9% ... Training loss: 0.104 ... Validation loss: 0.235[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 18.0% ... Training loss: 0.123 ... Validation loss: 0.271[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 18.0% ... Training loss: 0.107 ... Validation loss: 0.192[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 18.1% ... Training loss: 0.096 ... Validation loss: 0.180[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 18.2% ... Training loss: 0.093 ... Validation loss: 0.193[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 18.2% ... Training loss: 0.081 ... Validation loss: 0.173[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 18.3% ... Training loss: 0.079 ... Validation loss: 0.154[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 18.4% ... Training loss: 0.086 ... Validation loss: 0.180[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 18.4% ... Training loss: 0.086 ... Validation loss: 0.178[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 18.5% ... Training loss: 0.085 ... Validation loss: 0.173[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 18.6% ... Training loss: 0.083 ... Validation loss: 0.177[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 18.6% ... Training loss: 0.140 ... Validation loss: 0.205[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 18.7% ... Training loss: 0.156 ... Validation loss: 0.231[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 18.8% ... Training loss: 0.096 ... Validation loss: 0.167[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 18.8% ... Training loss: 0.112 ... Validation loss: 0.220[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 18.9% ... Training loss: 0.147 ... Validation loss: 0.196[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 19.0% ... Training loss: 0.087 ... Validation loss: 0.172[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 19.0% ... Training loss: 0.103 ... Validation loss: 0.170[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 19.1% ... Training loss: 0.084 ... Validation loss: 0.207[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 19.2% ... Training loss: 0.144 ... Validation loss: 0.297[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 19.2% ... Training loss: 0.148 ... Validation loss: 0.218[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 19.3% ... Training loss: 0.086 ... Validation loss: 0.167[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 19.4% ... Training loss: 0.089 ... Validation loss: 0.166[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 19.4% ... Training loss: 0.080 ... Validation loss: 0.173[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 19.5% ... Training loss: 0.099 ... Validation loss: 0.212[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 19.6% ... Training loss: 0.094 ... Validation loss: 0.207[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 19.6% ... Training loss: 0.091 ... Validation loss: 0.168[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 19.7% ... Training loss: 0.096 ... Validation loss: 0.233[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 19.8% ... Training loss: 0.083 ... Validation loss: 0.190[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 19.8% ... Training loss: 0.087 ... Validation loss: 0.176[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 19.9% ... Training loss: 0.107 ... Validation loss: 0.236[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 20.0% ... Training loss: 0.086 ... Validation loss: 0.170[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 20.0% ... Training loss: 0.082 ... Validation loss: 0.178[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 20.1% ... Training loss: 0.099 ... Validation loss: 0.190[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 20.2% ... Training loss: 0.095 ... Validation loss: 0.195[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 20.2% ... Training loss: 0.089 ... Validation loss: 0.181[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 20.3% ... Training loss: 0.086 ... Validation loss: 0.199[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 20.4% ... Training loss: 0.077 ... Validation loss: 0.184[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 20.4% ... Training loss: 0.091 ... Validation loss: 0.202[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 20.5% ... Training loss: 0.083 ... Validation loss: 0.187[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 20.6% ... Training loss: 0.107 ... Validation loss: 0.273[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 20.6% ... Training loss: 0.090 ... Validation loss: 0.195[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 20.7% ... Training loss: 0.099 ... Validation loss: 0.186[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 20.8% ... Training loss: 0.091 ... Validation loss: 0.174[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 20.8% ... Training loss: 0.095 ... Validation loss: 0.178[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 20.9% ... Training loss: 0.098 ... Validation loss: 0.248[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 21.0% ... Training loss: 0.082 ... Validation loss: 0.170[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 21.0% ... Training loss: 0.096 ... Validation loss: 0.190[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 21.1% ... Training loss: 0.075 ... Validation loss: 0.165[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 21.2% ... Training loss: 0.097 ... Validation loss: 0.249[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 21.2% ... Training loss: 0.106 ... Validation loss: 0.215[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 21.3% ... Training loss: 0.092 ... Validation loss: 0.171[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 21.4% ... Training loss: 0.091 ... Validation loss: 0.188[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 21.4% ... Training loss: 0.083 ... Validation loss: 0.190[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 21.5% ... Training loss: 0.086 ... Validation loss: 0.213[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 21.6% ... Training loss: 0.084 ... Validation loss: 0.207[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 21.6% ... Training loss: 0.094 ... Validation loss: 0.210[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 21.7% ... Training loss: 0.080 ... Validation loss: 0.190[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 21.8% ... Training loss: 0.099 ... Validation loss: 0.217[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 21.8% ... Training loss: 0.078 ... Validation loss: 0.177[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 21.9% ... Training loss: 0.084 ... Validation loss: 0.222[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 22.0% ... Training loss: 0.082 ... Validation loss: 0.242[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 22.0% ... Training loss: 0.098 ... Validation loss: 0.248[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 22.1% ... Training loss: 0.093 ... Validation loss: 0.227[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 22.2% ... Training loss: 0.078 ... Validation loss: 0.241[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 22.2% ... Training loss: 0.080 ... Validation loss: 0.221[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 22.3% ... Training loss: 0.100 ... Validation loss: 0.292[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 22.4% ... Training loss: 0.098 ... Validation loss: 0.340[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 22.4% ... Training loss: 0.094 ... Validation loss: 0.236[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 22.5% ... Training loss: 0.100 ... Validation loss: 0.235[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 22.6% ... Training loss: 0.091 ... Validation loss: 0.182[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 22.6% ... Training loss: 0.091 ... Validation loss: 0.219[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 22.7% ... Training loss: 0.090 ... Validation loss: 0.198[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 22.8% ... Training loss: 0.128 ... Validation loss: 0.205[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 22.8% ... Training loss: 0.124 ... Validation loss: 0.247[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 22.9% ... Training loss: 0.107 ... Validation loss: 0.205[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 23.0% ... Training loss: 0.114 ... Validation loss: 0.207[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 23.0% ... Training loss: 0.116 ... Validation loss: 0.203[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 23.1% ... Training loss: 0.099 ... Validation loss: 0.194[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 23.2% ... Training loss: 0.110 ... Validation loss: 0.196[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 23.2% ... Training loss: 0.099 ... Validation loss: 0.187[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 23.3% ... Training loss: 0.092 ... Validation loss: 0.188[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 23.4% ... Training loss: 0.093 ... Validation loss: 0.199[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 23.4% ... Training loss: 0.089 ... Validation loss: 0.212[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 23.5% ... Training loss: 0.118 ... Validation loss: 0.204[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 23.6% ... Training loss: 0.124 ... Validation loss: 0.321[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 23.6% ... Training loss: 0.101 ... Validation loss: 0.193[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 23.7% ... Training loss: 0.127 ... Validation loss: 0.188[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 23.8% ... Training loss: 0.087 ... Validation loss: 0.192[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 23.8% ... Training loss: 0.121 ... Validation loss: 0.234[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 23.9% ... Training loss: 0.183 ... Validation loss: 0.299[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 24.0% ... Training loss: 0.094 ... Validation loss: 0.211[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 24.0% ... Training loss: 0.092 ... Validation loss: 0.181[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 24.1% ... Training loss: 0.124 ... Validation loss: 0.228[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 24.2% ... Training loss: 0.087 ... Validation loss: 0.200[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 24.2% ... Training loss: 0.096 ... Validation loss: 0.203[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 24.3% ... Training loss: 0.098 ... Validation loss: 0.207[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 24.4% ... Training loss: 0.090 ... Validation loss: 0.252[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 24.4% ... Training loss: 0.083 ... Validation loss: 0.183[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 24.5% ... Training loss: 0.104 ... Validation loss: 0.303[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 24.6% ... Training loss: 0.080 ... Validation loss: 0.163[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 24.6% ... Training loss: 0.083 ... Validation loss: 0.169[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 24.7% ... Training loss: 0.086 ... Validation loss: 0.183[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 24.8% ... Training loss: 0.095 ... Validation loss: 0.196[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 24.8% ... Training loss: 0.075 ... Validation loss: 0.172[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 24.9% ... Training loss: 0.084 ... Validation loss: 0.164[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 25.0% ... Training loss: 0.093 ... Validation loss: 0.177[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 25.0% ... Training loss: 0.091 ... Validation loss: 0.182[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 25.1% ... Training loss: 0.073 ... Validation loss: 0.200[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 25.2% ... Training loss: 0.089 ... Validation loss: 0.182[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 25.2% ... Training loss: 0.084 ... Validation loss: 0.196[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 25.3% ... Training loss: 0.101 ... Validation loss: 0.183[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 25.4% ... Training loss: 0.086 ... Validation loss: 0.194[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 25.4% ... Training loss: 0.083 ... Validation loss: 0.153[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 25.5% ... Training loss: 0.083 ... Validation loss: 0.167[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 25.6% ... Training loss: 0.086 ... Validation loss: 0.191[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 25.6% ... Training loss: 0.099 ... Validation loss: 0.224[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 25.7% ... Training loss: 0.090 ... Validation loss: 0.178[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 25.8% ... Training loss: 0.117 ... Validation loss: 0.255[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 25.8% ... Training loss: 0.096 ... Validation loss: 0.216[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 25.9% ... Training loss: 0.099 ... Validation loss: 0.203[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 26.0% ... Training loss: 0.089 ... Validation loss: 0.180[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 26.0% ... Training loss: 0.093 ... Validation loss: 0.182[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 26.1% ... Training loss: 0.082 ... Validation loss: 0.169[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 26.2% ... Training loss: 0.103 ... Validation loss: 0.168[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 26.2% ... Training loss: 0.082 ... Validation loss: 0.165[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 26.3% ... Training loss: 0.093 ... Validation loss: 0.224[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 26.4% ... Training loss: 0.084 ... Validation loss: 0.171[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 26.4% ... Training loss: 0.088 ... Validation loss: 0.172[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 26.5% ... Training loss: 0.085 ... Validation loss: 0.172[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 26.6% ... Training loss: 0.095 ... Validation loss: 0.168[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 26.6% ... Training loss: 0.089 ... Validation loss: 0.190[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 26.7% ... Training loss: 0.089 ... Validation loss: 0.187[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 26.8% ... Training loss: 0.086 ... Validation loss: 0.178[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 26.8% ... Training loss: 0.076 ... Validation loss: 0.157[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 26.9% ... Training loss: 0.079 ... Validation loss: 0.167[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 27.0% ... Training loss: 0.095 ... Validation loss: 0.208[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 27.0% ... Training loss: 0.103 ... Validation loss: 0.172[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 27.1% ... Training loss: 0.079 ... Validation loss: 0.171[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 27.2% ... Training loss: 0.089 ... Validation loss: 0.177[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 27.2% ... Training loss: 0.078 ... Validation loss: 0.162[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 27.3% ... Training loss: 0.087 ... Validation loss: 0.185[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 27.4% ... Training loss: 0.108 ... Validation loss: 0.215[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 27.4% ... Training loss: 0.079 ... Validation loss: 0.174[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 27.5% ... Training loss: 0.085 ... Validation loss: 0.183[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 27.6% ... Training loss: 0.083 ... Validation loss: 0.180[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 27.6% ... Training loss: 0.081 ... Validation loss: 0.177[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 27.7% ... Training loss: 0.078 ... Validation loss: 0.186[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 27.8% ... Training loss: 0.074 ... Validation loss: 0.185[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 27.8% ... Training loss: 0.073 ... Validation loss: 0.179[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 27.9% ... Training loss: 0.084 ... Validation loss: 0.186[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 28.0% ... Training loss: 0.079 ... Validation loss: 0.236[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 28.0% ... Training loss: 0.092 ... Validation loss: 0.213[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 28.1% ... Training loss: 0.073 ... Validation loss: 0.208[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 28.2% ... Training loss: 0.080 ... Validation loss: 0.201[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 28.2% ... Training loss: 0.078 ... Validation loss: 0.210[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 28.3% ... Training loss: 0.078 ... Validation loss: 0.188[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 28.4% ... Training loss: 0.103 ... Validation loss: 0.218[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 28.4% ... Training loss: 0.080 ... Validation loss: 0.183[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 28.5% ... Training loss: 0.112 ... Validation loss: 0.291[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 28.6% ... Training loss: 0.093 ... Validation loss: 0.240[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 28.6% ... Training loss: 0.116 ... Validation loss: 0.265[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 28.7% ... Training loss: 0.076 ... Validation loss: 0.162[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 28.8% ... Training loss: 0.083 ... Validation loss: 0.183[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 28.8% ... Training loss: 0.078 ... Validation loss: 0.181[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 28.9% ... Training loss: 0.075 ... Validation loss: 0.189[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 29.0% ... Training loss: 0.077 ... Validation loss: 0.188[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 29.0% ... Training loss: 0.097 ... Validation loss: 0.167[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 29.1% ... Training loss: 0.093 ... Validation loss: 0.182[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 29.2% ... Training loss: 0.099 ... Validation loss: 0.240[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 29.2% ... Training loss: 0.080 ... Validation loss: 0.164[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 29.3% ... Training loss: 0.091 ... Validation loss: 0.202[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 29.4% ... Training loss: 0.101 ... Validation loss: 0.172[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 29.4% ... Training loss: 0.109 ... Validation loss: 0.263[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 29.5% ... Training loss: 0.096 ... Validation loss: 0.197[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 29.6% ... Training loss: 0.085 ... Validation loss: 0.172[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 29.6% ... Training loss: 0.098 ... Validation loss: 0.195[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 29.7% ... Training loss: 0.077 ... Validation loss: 0.175[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 29.8% ... Training loss: 0.080 ... Validation loss: 0.170[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 29.8% ... Training loss: 0.086 ... Validation loss: 0.170[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 29.9% ... Training loss: 0.088 ... Validation loss: 0.230[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 30.0% ... Training loss: 0.078 ... Validation loss: 0.176[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 30.0% ... Training loss: 0.140 ... Validation loss: 0.212[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 30.1% ... Training loss: 0.097 ... Validation loss: 0.220[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 30.2% ... Training loss: 0.087 ... Validation loss: 0.219[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 30.2% ... Training loss: 0.089 ... Validation loss: 0.217[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 30.3% ... Training loss: 0.078 ... Validation loss: 0.188[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 30.4% ... Training loss: 0.075 ... Validation loss: 0.222[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 30.4% ... Training loss: 0.076 ... Validation loss: 0.208[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 30.5% ... Training loss: 0.084 ... Validation loss: 0.244[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 30.6% ... Training loss: 0.079 ... Validation loss: 0.181[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 30.6% ... Training loss: 0.077 ... Validation loss: 0.204[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 30.7% ... Training loss: 0.079 ... Validation loss: 0.173[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 30.8% ... Training loss: 0.093 ... Validation loss: 0.186[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 30.8% ... Training loss: 0.083 ... Validation loss: 0.182[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 30.9% ... Training loss: 0.081 ... Validation loss: 0.206[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 31.0% ... Training loss: 0.099 ... Validation loss: 0.239[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 31.0% ... Training loss: 0.070 ... Validation loss: 0.180[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 31.1% ... Training loss: 0.081 ... Validation loss: 0.204[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 31.2% ... Training loss: 0.083 ... Validation loss: 0.176[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 31.2% ... Training loss: 0.084 ... Validation loss: 0.171[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 31.3% ... Training loss: 0.079 ... Validation loss: 0.199[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 31.4% ... Training loss: 0.077 ... Validation loss: 0.208[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 31.4% ... Training loss: 0.078 ... Validation loss: 0.199[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 31.5% ... Training loss: 0.084 ... Validation loss: 0.186[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 31.6% ... Training loss: 0.071 ... Validation loss: 0.159[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 31.6% ... Training loss: 0.073 ... Validation loss: 0.170[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 31.7% ... Training loss: 0.076 ... Validation loss: 0.168[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 31.8% ... Training loss: 0.079 ... Validation loss: 0.168[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 31.8% ... Training loss: 0.106 ... Validation loss: 0.227[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 31.9% ... Training loss: 0.076 ... Validation loss: 0.179[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 32.0% ... Training loss: 0.102 ... Validation loss: 0.244[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 32.0% ... Training loss: 0.090 ... Validation loss: 0.192[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 32.1% ... Training loss: 0.088 ... Validation loss: 0.234[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 32.2% ... Training loss: 0.074 ... Validation loss: 0.188[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 32.2% ... Training loss: 0.090 ... Validation loss: 0.198[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 32.3% ... Training loss: 0.082 ... Validation loss: 0.199[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 32.4% ... Training loss: 0.094 ... Validation loss: 0.218[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 32.4% ... Training loss: 0.098 ... Validation loss: 0.257[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 32.5% ... Training loss: 0.094 ... Validation loss: 0.209[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 32.6% ... Training loss: 0.073 ... Validation loss: 0.192[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 32.6% ... Training loss: 0.073 ... Validation loss: 0.187[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 32.7% ... Training loss: 0.131 ... Validation loss: 0.205[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 32.8% ... Training loss: 0.084 ... Validation loss: 0.172[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 32.8% ... Training loss: 0.070 ... Validation loss: 0.162[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 32.9% ... Training loss: 0.090 ... Validation loss: 0.164[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 33.0% ... Training loss: 0.073 ... Validation loss: 0.165[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 33.0% ... Training loss: 0.091 ... Validation loss: 0.180[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 33.1% ... Training loss: 0.112 ... Validation loss: 0.187[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 33.2% ... Training loss: 0.083 ... Validation loss: 0.217[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 33.2% ... Training loss: 0.087 ... Validation loss: 0.215[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 33.3% ... Training loss: 0.079 ... Validation loss: 0.163[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 33.4% ... Training loss: 0.107 ... Validation loss: 0.209[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 33.4% ... Training loss: 0.096 ... Validation loss: 0.175[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 33.5% ... Training loss: 0.091 ... Validation loss: 0.175[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 33.6% ... Training loss: 0.092 ... Validation loss: 0.197[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 33.6% ... Training loss: 0.077 ... Validation loss: 0.179[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 33.7% ... Training loss: 0.099 ... Validation loss: 0.202[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 33.8% ... Training loss: 0.089 ... Validation loss: 0.200[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 33.8% ... Training loss: 0.116 ... Validation loss: 0.196[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 33.9% ... Training loss: 0.092 ... Validation loss: 0.219[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 34.0% ... Training loss: 0.104 ... Validation loss: 0.193[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 34.0% ... Training loss: 0.093 ... Validation loss: 0.199[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 34.1% ... Training loss: 0.071 ... Validation loss: 0.173[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 34.2% ... Training loss: 0.081 ... Validation loss: 0.172[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 34.2% ... Training loss: 0.090 ... Validation loss: 0.198[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 34.3% ... Training loss: 0.094 ... Validation loss: 0.185[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 34.4% ... Training loss: 0.084 ... Validation loss: 0.222[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 34.4% ... Training loss: 0.084 ... Validation loss: 0.208[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 34.5% ... Training loss: 0.069 ... Validation loss: 0.206[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 34.6% ... Training loss: 0.071 ... Validation loss: 0.174[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 34.6% ... Training loss: 0.094 ... Validation loss: 0.208[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 34.7% ... Training loss: 0.093 ... Validation loss: 0.205[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 34.8% ... Training loss: 0.082 ... Validation loss: 0.179[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 34.8% ... Training loss: 0.093 ... Validation loss: 0.185[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 34.9% ... Training loss: 0.078 ... Validation loss: 0.160[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 35.0% ... Training loss: 0.084 ... Validation loss: 0.178[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 35.0% ... Training loss: 0.082 ... Validation loss: 0.240[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 35.1% ... Training loss: 0.084 ... Validation loss: 0.192[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 35.2% ... Training loss: 0.082 ... Validation loss: 0.177[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 35.2% ... Training loss: 0.086 ... Validation loss: 0.179[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 35.3% ... Training loss: 0.083 ... Validation loss: 0.194[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 35.4% ... Training loss: 0.087 ... Validation loss: 0.176[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 35.4% ... Training loss: 0.081 ... Validation loss: 0.178[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 35.5% ... Training loss: 0.092 ... Validation loss: 0.208[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 35.6% ... Training loss: 0.079 ... Validation loss: 0.196[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 35.6% ... Training loss: 0.072 ... Validation loss: 0.161[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 35.7% ... Training loss: 0.100 ... Validation loss: 0.175[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 35.8% ... Training loss: 0.074 ... Validation loss: 0.174[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 35.8% ... Training loss: 0.072 ... Validation loss: 0.166[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 35.9% ... Training loss: 0.076 ... Validation loss: 0.191[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 36.0% ... Training loss: 0.076 ... Validation loss: 0.183[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 36.0% ... Training loss: 0.094 ... Validation loss: 0.223[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 36.1% ... Training loss: 0.092 ... Validation loss: 0.172[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 36.2% ... Training loss: 0.076 ... Validation loss: 0.183[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 36.2% ... Training loss: 0.073 ... Validation loss: 0.173[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 36.3% ... Training loss: 0.119 ... Validation loss: 0.181[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 36.4% ... Training loss: 0.084 ... Validation loss: 0.195[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 36.4% ... Training loss: 0.087 ... Validation loss: 0.197[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 36.5% ... Training loss: 0.072 ... Validation loss: 0.186[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 36.6% ... Training loss: 0.083 ... Validation loss: 0.252[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 36.6% ... Training loss: 0.083 ... Validation loss: 0.216[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 36.7% ... Training loss: 0.094 ... Validation loss: 0.282[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 36.8% ... Training loss: 0.073 ... Validation loss: 0.214[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 36.8% ... Training loss: 0.116 ... Validation loss: 0.185[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 36.9% ... Training loss: 0.087 ... Validation loss: 0.281[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 37.0% ... Training loss: 0.082 ... Validation loss: 0.189[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 37.0% ... Training loss: 0.085 ... Validation loss: 0.168[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 37.1% ... Training loss: 0.085 ... Validation loss: 0.188[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 37.2% ... Training loss: 0.097 ... Validation loss: 0.182[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 37.2% ... Training loss: 0.073 ... Validation loss: 0.166[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 37.3% ... Training loss: 0.101 ... Validation loss: 0.239[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 37.4% ... Training loss: 0.084 ... Validation loss: 0.171[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 37.4% ... Training loss: 0.109 ... Validation loss: 0.346[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 37.5% ... Training loss: 0.091 ... Validation loss: 0.207[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 37.6% ... Training loss: 0.084 ... Validation loss: 0.186[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 37.6% ... Training loss: 0.098 ... Validation loss: 0.255[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 37.7% ... Training loss: 0.116 ... Validation loss: 0.285[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 37.8% ... Training loss: 0.088 ... Validation loss: 0.199[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 37.8% ... Training loss: 0.091 ... Validation loss: 0.203[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 37.9% ... Training loss: 0.108 ... Validation loss: 0.182[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 38.0% ... Training loss: 0.121 ... Validation loss: 0.178[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 38.0% ... Training loss: 0.075 ... Validation loss: 0.167[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 38.1% ... Training loss: 0.082 ... Validation loss: 0.166[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 38.2% ... Training loss: 0.085 ... Validation loss: 0.179[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 38.2% ... Training loss: 0.138 ... Validation loss: 0.224[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 38.3% ... Training loss: 0.072 ... Validation loss: 0.167[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 38.4% ... Training loss: 0.096 ... Validation loss: 0.160[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 38.4% ... Training loss: 0.086 ... Validation loss: 0.181[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 38.5% ... Training loss: 0.074 ... Validation loss: 0.178[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 38.6% ... Training loss: 0.094 ... Validation loss: 0.183[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 38.6% ... Training loss: 0.100 ... Validation loss: 0.196[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 38.7% ... Training loss: 0.093 ... Validation loss: 0.176[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 38.8% ... Training loss: 0.077 ... Validation loss: 0.169[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 38.8% ... Training loss: 0.081 ... Validation loss: 0.194[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 38.9% ... Training loss: 0.101 ... Validation loss: 0.193[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 39.0% ... Training loss: 0.087 ... Validation loss: 0.164[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 39.0% ... Training loss: 0.078 ... Validation loss: 0.171[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 39.1% ... Training loss: 0.095 ... Validation loss: 0.205[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 39.2% ... Training loss: 0.100 ... Validation loss: 0.220[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 39.2% ... Training loss: 0.092 ... Validation loss: 0.219[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 39.3% ... Training loss: 0.098 ... Validation loss: 0.230[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 39.4% ... Training loss: 0.204 ... Validation loss: 0.269[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 39.4% ... Training loss: 0.076 ... Validation loss: 0.188[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 39.5% ... Training loss: 0.084 ... Validation loss: 0.189[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 39.6% ... Training loss: 0.079 ... Validation loss: 0.195[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 39.6% ... Training loss: 0.100 ... Validation loss: 0.185[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 39.7% ... Training loss: 0.078 ... Validation loss: 0.169[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 39.8% ... Training loss: 0.080 ... Validation loss: 0.172[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 39.8% ... Training loss: 0.080 ... Validation loss: 0.235[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 39.9% ... Training loss: 0.097 ... Validation loss: 0.273[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 40.0% ... Training loss: 0.069 ... Validation loss: 0.187[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 40.0% ... Training loss: 0.083 ... Validation loss: 0.187[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 40.1% ... Training loss: 0.076 ... Validation loss: 0.171[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 40.2% ... Training loss: 0.090 ... Validation loss: 0.197[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 40.2% ... Training loss: 0.069 ... Validation loss: 0.161[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 40.3% ... Training loss: 0.067 ... Validation loss: 0.180[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 40.4% ... Training loss: 0.066 ... Validation loss: 0.184[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 40.4% ... Training loss: 0.090 ... Validation loss: 0.308[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 40.5% ... Training loss: 0.077 ... Validation loss: 0.180[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 40.6% ... Training loss: 0.085 ... Validation loss: 0.163[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 40.6% ... Training loss: 0.074 ... Validation loss: 0.188[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 40.7% ... Training loss: 0.120 ... Validation loss: 0.295[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 40.8% ... Training loss: 0.080 ... Validation loss: 0.200[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 40.8% ... Training loss: 0.097 ... Validation loss: 0.251[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 40.9% ... Training loss: 0.083 ... Validation loss: 0.191[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 41.0% ... Training loss: 0.086 ... Validation loss: 0.209[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 41.0% ... Training loss: 0.088 ... Validation loss: 0.193[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 41.1% ... Training loss: 0.082 ... Validation loss: 0.235[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 41.2% ... Training loss: 0.073 ... Validation loss: 0.207[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 41.2% ... Training loss: 0.089 ... Validation loss: 0.223[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 41.3% ... Training loss: 0.087 ... Validation loss: 0.188[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 41.4% ... Training loss: 0.079 ... Validation loss: 0.214[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 41.4% ... Training loss: 0.086 ... Validation loss: 0.185[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 41.5% ... Training loss: 0.076 ... Validation loss: 0.204[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 41.6% ... Training loss: 0.080 ... Validation loss: 0.182[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 41.6% ... Training loss: 0.088 ... Validation loss: 0.219[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 41.7% ... Training loss: 0.087 ... Validation loss: 0.187[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 41.8% ... Training loss: 0.090 ... Validation loss: 0.168[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 41.8% ... Training loss: 0.089 ... Validation loss: 0.199[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 41.9% ... Training loss: 0.079 ... Validation loss: 0.192[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 42.0% ... Training loss: 0.080 ... Validation loss: 0.168[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 42.0% ... Training loss: 0.085 ... Validation loss: 0.175[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 42.1% ... Training loss: 0.076 ... Validation loss: 0.178[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 42.2% ... Training loss: 0.074 ... Validation loss: 0.182[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 42.2% ... Training loss: 0.091 ... Validation loss: 0.201[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 42.3% ... Training loss: 0.082 ... Validation loss: 0.180[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 42.4% ... Training loss: 0.085 ... Validation loss: 0.169[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 42.4% ... Training loss: 0.078 ... Validation loss: 0.168[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 42.5% ... Training loss: 0.077 ... Validation loss: 0.165[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 42.6% ... Training loss: 0.099 ... Validation loss: 0.223[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 42.6% ... Training loss: 0.095 ... Validation loss: 0.162[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 42.7% ... Training loss: 0.080 ... Validation loss: 0.196[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 42.8% ... Training loss: 0.078 ... Validation loss: 0.173[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 42.8% ... Training loss: 0.082 ... Validation loss: 0.168[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 42.9% ... Training loss: 0.075 ... Validation loss: 0.176[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 43.0% ... Training loss: 0.089 ... Validation loss: 0.220[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 43.0% ... Training loss: 0.083 ... Validation loss: 0.179[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 43.1% ... Training loss: 0.067 ... Validation loss: 0.191[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 43.2% ... Training loss: 0.087 ... Validation loss: 0.188[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 43.2% ... Training loss: 0.073 ... Validation loss: 0.177[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 43.3% ... Training loss: 0.073 ... Validation loss: 0.199[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 43.4% ... Training loss: 0.083 ... Validation loss: 0.286[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 43.4% ... Training loss: 0.077 ... Validation loss: 0.259[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 43.5% ... Training loss: 0.080 ... Validation loss: 0.202[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 43.6% ... Training loss: 0.077 ... Validation loss: 0.183[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 43.6% ... Training loss: 0.102 ... Validation loss: 0.362[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 43.7% ... Training loss: 0.113 ... Validation loss: 0.271[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 43.8% ... Training loss: 0.099 ... Validation loss: 0.226[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 43.8% ... Training loss: 0.103 ... Validation loss: 0.241[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 43.9% ... Training loss: 0.098 ... Validation loss: 0.165[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 44.0% ... Training loss: 0.084 ... Validation loss: 0.248[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 44.0% ... Training loss: 0.113 ... Validation loss: 0.226[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 44.1% ... Training loss: 0.075 ... Validation loss: 0.231[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 44.2% ... Training loss: 0.090 ... Validation loss: 0.176[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 44.2% ... Training loss: 0.076 ... Validation loss: 0.221[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 44.3% ... Training loss: 0.082 ... Validation loss: 0.236[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 44.4% ... Training loss: 0.103 ... Validation loss: 0.252[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 44.4% ... Training loss: 0.085 ... Validation loss: 0.185[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 44.5% ... Training loss: 0.086 ... Validation loss: 0.168[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 44.6% ... Training loss: 0.089 ... Validation loss: 0.161[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 44.6% ... Training loss: 0.091 ... Validation loss: 0.241[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 44.7% ... Training loss: 0.083 ... Validation loss: 0.201[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 44.8% ... Training loss: 0.078 ... Validation loss: 0.242[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 44.8% ... Training loss: 0.073 ... Validation loss: 0.227[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 44.9% ... Training loss: 0.078 ... Validation loss: 0.200[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 45.0% ... Training loss: 0.086 ... Validation loss: 0.256[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 45.0% ... Training loss: 0.105 ... Validation loss: 0.315[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 45.1% ... Training loss: 0.100 ... Validation loss: 0.240[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 45.2% ... Training loss: 0.079 ... Validation loss: 0.193[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 45.2% ... Training loss: 0.073 ... Validation loss: 0.181[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 45.3% ... Training loss: 0.086 ... Validation loss: 0.168[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 45.4% ... Training loss: 0.079 ... Validation loss: 0.177[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 45.4% ... Training loss: 0.084 ... Validation loss: 0.183[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 45.5% ... Training loss: 0.076 ... Validation loss: 0.167[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 45.6% ... Training loss: 0.092 ... Validation loss: 0.216[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 45.6% ... Training loss: 0.075 ... Validation loss: 0.166[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 45.7% ... Training loss: 0.069 ... Validation loss: 0.178[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 45.8% ... Training loss: 0.098 ... Validation loss: 0.183[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 45.8% ... Training loss: 0.085 ... Validation loss: 0.170[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 45.9% ... Training loss: 0.077 ... Validation loss: 0.170[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 46.0% ... Training loss: 0.076 ... Validation loss: 0.216[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 46.0% ... Training loss: 0.087 ... Validation loss: 0.189[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 46.1% ... Training loss: 0.089 ... Validation loss: 0.304[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 46.2% ... Training loss: 0.085 ... Validation loss: 0.226[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 46.2% ... Training loss: 0.077 ... Validation loss: 0.245[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 46.3% ... Training loss: 0.075 ... Validation loss: 0.234[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 46.4% ... Training loss: 0.074 ... Validation loss: 0.197[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 46.4% ... Training loss: 0.074 ... Validation loss: 0.235[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 46.5% ... Training loss: 0.105 ... Validation loss: 0.264[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 46.6% ... Training loss: 0.269 ... Validation loss: 0.483[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 46.6% ... Training loss: 0.100 ... Validation loss: 0.215[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 46.7% ... Training loss: 0.091 ... Validation loss: 0.220[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 46.8% ... Training loss: 0.072 ... Validation loss: 0.193[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 46.8% ... Training loss: 0.086 ... Validation loss: 0.214[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 46.9% ... Training loss: 0.075 ... Validation loss: 0.183[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 47.0% ... Training loss: 0.097 ... Validation loss: 0.201[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 47.0% ... Training loss: 0.069 ... Validation loss: 0.196[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 47.1% ... Training loss: 0.070 ... Validation loss: 0.200[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 47.2% ... Training loss: 0.106 ... Validation loss: 0.196[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 47.2% ... Training loss: 0.091 ... Validation loss: 0.183[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 47.3% ... Training loss: 0.094 ... Validation loss: 0.197[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 47.4% ... Training loss: 0.105 ... Validation loss: 0.197[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 47.4% ... Training loss: 0.070 ... Validation loss: 0.181[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 47.5% ... Training loss: 0.072 ... Validation loss: 0.189[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 47.6% ... Training loss: 0.143 ... Validation loss: 0.201[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 47.6% ... Training loss: 0.083 ... Validation loss: 0.203[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 47.7% ... Training loss: 0.080 ... Validation loss: 0.165[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 47.8% ... Training loss: 0.072 ... Validation loss: 0.215[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 47.8% ... Training loss: 0.221 ... Validation loss: 0.290[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 47.9% ... Training loss: 0.075 ... Validation loss: 0.209[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 48.0% ... Training loss: 0.069 ... Validation loss: 0.221[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 48.0% ... Training loss: 0.073 ... Validation loss: 0.230[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 48.1% ... Training loss: 0.071 ... Validation loss: 0.173[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 48.2% ... Training loss: 0.120 ... Validation loss: 0.251[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 48.2% ... Training loss: 0.080 ... Validation loss: 0.221[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 48.3% ... Training loss: 0.081 ... Validation loss: 0.279[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 48.4% ... Training loss: 0.078 ... Validation loss: 0.184[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 48.4% ... Training loss: 0.089 ... Validation loss: 0.166[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 48.5% ... Training loss: 0.083 ... Validation loss: 0.195[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 48.6% ... Training loss: 0.068 ... Validation loss: 0.226[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 48.6% ... Training loss: 0.075 ... Validation loss: 0.209[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 48.7% ... Training loss: 0.086 ... Validation loss: 0.233[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 48.8% ... Training loss: 0.089 ... Validation loss: 0.247[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 48.8% ... Training loss: 0.088 ... Validation loss: 0.191[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 48.9% ... Training loss: 0.072 ... Validation loss: 0.199[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 49.0% ... Training loss: 0.075 ... Validation loss: 0.206[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 49.0% ... Training loss: 0.073 ... Validation loss: 0.179[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 49.1% ... Training loss: 0.070 ... Validation loss: 0.184[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 49.2% ... Training loss: 0.091 ... Validation loss: 0.273[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 49.2% ... Training loss: 0.068 ... Validation loss: 0.206[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 49.3% ... Training loss: 0.080 ... Validation loss: 0.277[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 49.4% ... Training loss: 0.083 ... Validation loss: 0.246[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 49.4% ... Training loss: 0.073 ... Validation loss: 0.247[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 49.5% ... Training loss: 0.084 ... Validation loss: 0.278[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 49.6% ... Training loss: 0.074 ... Validation loss: 0.286[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 49.6% ... Training loss: 0.076 ... Validation loss: 0.214[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 49.7% ... Training loss: 0.068 ... Validation loss: 0.176[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 49.8% ... Training loss: 0.103 ... Validation loss: 0.232[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 49.8% ... Training loss: 0.080 ... Validation loss: 0.265[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 49.9% ... Training loss: 0.077 ... Validation loss: 0.205[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 50.0% ... Training loss: 0.079 ... Validation loss: 0.192[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 50.0% ... Training loss: 0.074 ... Validation loss: 0.187[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 50.1% ... Training loss: 0.104 ... Validation loss: 0.188[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 50.2% ... Training loss: 0.076 ... Validation loss: 0.197[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 50.2% ... Training loss: 0.078 ... Validation loss: 0.195[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 50.3% ... Training loss: 0.080 ... Validation loss: 0.212[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 50.4% ... Training loss: 0.088 ... Validation loss: 0.182[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 50.4% ... Training loss: 0.070 ... Validation loss: 0.169[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 50.5% ... Training loss: 0.076 ... Validation loss: 0.163[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 50.6% ... Training loss: 0.076 ... Validation loss: 0.163[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 50.6% ... Training loss: 0.070 ... Validation loss: 0.187[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 50.7% ... Training loss: 0.066 ... Validation loss: 0.200[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 50.8% ... Training loss: 0.076 ... Validation loss: 0.186[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 50.8% ... Training loss: 0.061 ... Validation loss: 0.174[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 50.9% ... Training loss: 0.067 ... Validation loss: 0.209[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 51.0% ... Training loss: 0.088 ... Validation loss: 0.257[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 51.0% ... Training loss: 0.077 ... Validation loss: 0.204[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 51.1% ... Training loss: 0.072 ... Validation loss: 0.233[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 51.2% ... Training loss: 0.077 ... Validation loss: 0.213[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 51.2% ... Training loss: 0.110 ... Validation loss: 0.187[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 51.3% ... Training loss: 0.083 ... Validation loss: 0.212[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 51.4% ... Training loss: 0.076 ... Validation loss: 0.213[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 51.4% ... Training loss: 0.076 ... Validation loss: 0.275[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 51.5% ... Training loss: 0.073 ... Validation loss: 0.230[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 51.6% ... Training loss: 0.069 ... Validation loss: 0.177[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 51.6% ... Training loss: 0.079 ... Validation loss: 0.161[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 51.7% ... Training loss: 0.109 ... Validation loss: 0.266[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 51.8% ... Training loss: 0.063 ... Validation loss: 0.210[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 51.8% ... Training loss: 0.066 ... Validation loss: 0.220[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 51.9% ... Training loss: 0.071 ... Validation loss: 0.256[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 52.0% ... Training loss: 0.074 ... Validation loss: 0.191[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 52.0% ... Training loss: 0.105 ... Validation loss: 0.344[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 52.1% ... Training loss: 0.077 ... Validation loss: 0.225[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 52.2% ... Training loss: 0.081 ... Validation loss: 0.186[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 52.2% ... Training loss: 0.072 ... Validation loss: 0.159[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 52.3% ... Training loss: 0.070 ... Validation loss: 0.179[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 52.4% ... Training loss: 0.069 ... Validation loss: 0.195[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 52.4% ... Training loss: 0.110 ... Validation loss: 0.214[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 52.5% ... Training loss: 0.081 ... Validation loss: 0.226[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 52.6% ... Training loss: 0.066 ... Validation loss: 0.183[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 52.6% ... Training loss: 0.082 ... Validation loss: 0.205[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 52.7% ... Training loss: 0.069 ... Validation loss: 0.207[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 52.8% ... Training loss: 0.078 ... Validation loss: 0.197[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 52.8% ... Training loss: 0.073 ... Validation loss: 0.180[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 52.9% ... Training loss: 0.073 ... Validation loss: 0.202[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 53.0% ... Training loss: 0.131 ... Validation loss: 0.237[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 53.0% ... Training loss: 0.080 ... Validation loss: 0.225[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 53.1% ... Training loss: 0.123 ... Validation loss: 0.263[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 53.2% ... Training loss: 0.099 ... Validation loss: 0.202[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 53.2% ... Training loss: 0.085 ... Validation loss: 0.235[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 53.3% ... Training loss: 0.082 ... Validation loss: 0.227[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 53.4% ... Training loss: 0.128 ... Validation loss: 0.237[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 53.4% ... Training loss: 0.107 ... Validation loss: 0.191[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 53.5% ... Training loss: 0.080 ... Validation loss: 0.210[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 53.6% ... Training loss: 0.067 ... Validation loss: 0.185[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 53.6% ... Training loss: 0.068 ... Validation loss: 0.168[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 53.7% ... Training loss: 0.085 ... Validation loss: 0.186[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 53.8% ... Training loss: 0.069 ... Validation loss: 0.195[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 53.8% ... Training loss: 0.072 ... Validation loss: 0.178[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 53.9% ... Training loss: 0.094 ... Validation loss: 0.210[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 54.0% ... Training loss: 0.109 ... Validation loss: 0.206[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 54.0% ... Training loss: 0.072 ... Validation loss: 0.165[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 54.1% ... Training loss: 0.072 ... Validation loss: 0.182[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 54.2% ... Training loss: 0.082 ... Validation loss: 0.186[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 54.2% ... Training loss: 0.071 ... Validation loss: 0.181[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 54.3% ... Training loss: 0.081 ... Validation loss: 0.209[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 54.4% ... Training loss: 0.070 ... Validation loss: 0.186[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 54.4% ... Training loss: 0.074 ... Validation loss: 0.208[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 54.5% ... Training loss: 0.105 ... Validation loss: 0.286[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 54.6% ... Training loss: 0.073 ... Validation loss: 0.198[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 54.6% ... Training loss: 0.069 ... Validation loss: 0.189[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 54.7% ... Training loss: 0.074 ... Validation loss: 0.219[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 54.8% ... Training loss: 0.086 ... Validation loss: 0.212[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 54.8% ... Training loss: 0.078 ... Validation loss: 0.211[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 54.9% ... Training loss: 0.069 ... Validation loss: 0.204[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 55.0% ... Training loss: 0.081 ... Validation loss: 0.185[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 55.0% ... Training loss: 0.093 ... Validation loss: 0.196[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 55.1% ... Training loss: 0.081 ... Validation loss: 0.234[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 55.2% ... Training loss: 0.104 ... Validation loss: 0.219[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 55.2% ... Training loss: 0.072 ... Validation loss: 0.235[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 55.3% ... Training loss: 0.079 ... Validation loss: 0.290[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 55.4% ... Training loss: 0.091 ... Validation loss: 0.219[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 55.4% ... Training loss: 0.084 ... Validation loss: 0.197[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 55.5% ... Training loss: 0.077 ... Validation loss: 0.178[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 55.6% ... Training loss: 0.077 ... Validation loss: 0.190[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 55.6% ... Training loss: 0.082 ... Validation loss: 0.216[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 55.7% ... Training loss: 0.075 ... Validation loss: 0.223[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 55.8% ... Training loss: 0.084 ... Validation loss: 0.236[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 55.8% ... Training loss: 0.094 ... Validation loss: 0.224[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 55.9% ... Training loss: 0.079 ... Validation loss: 0.171[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 56.0% ... Training loss: 0.088 ... Validation loss: 0.204[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 56.0% ... Training loss: 0.070 ... Validation loss: 0.180[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 56.1% ... Training loss: 0.076 ... Validation loss: 0.168[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 56.2% ... Training loss: 0.085 ... Validation loss: 0.181[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 56.2% ... Training loss: 0.075 ... Validation loss: 0.167[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 56.3% ... Training loss: 0.073 ... Validation loss: 0.216[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 56.4% ... Training loss: 0.106 ... Validation loss: 0.216[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 56.4% ... Training loss: 0.095 ... Validation loss: 0.218[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 56.5% ... Training loss: 0.079 ... Validation loss: 0.169[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 56.6% ... Training loss: 0.066 ... Validation loss: 0.157[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 56.6% ... Training loss: 0.074 ... Validation loss: 0.156[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 56.7% ... Training loss: 0.071 ... Validation loss: 0.248[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 56.8% ... Training loss: 0.083 ... Validation loss: 0.199[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 56.8% ... Training loss: 0.079 ... Validation loss: 0.194[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 56.9% ... Training loss: 0.069 ... Validation loss: 0.202[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 57.0% ... Training loss: 0.065 ... Validation loss: 0.186[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 57.0% ... Training loss: 0.084 ... Validation loss: 0.184[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 57.1% ... Training loss: 0.077 ... Validation loss: 0.219[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 57.2% ... Training loss: 0.095 ... Validation loss: 0.214[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 57.2% ... Training loss: 0.095 ... Validation loss: 0.188[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 57.3% ... Training loss: 0.074 ... Validation loss: 0.215[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 57.4% ... Training loss: 0.081 ... Validation loss: 0.165[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 57.4% ... Training loss: 0.147 ... Validation loss: 0.293[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 57.5% ... Training loss: 0.112 ... Validation loss: 0.201[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 57.6% ... Training loss: 0.070 ... Validation loss: 0.197[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 57.6% ... Training loss: 0.110 ... Validation loss: 0.240[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 57.7% ... Training loss: 0.076 ... Validation loss: 0.170[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 57.8% ... Training loss: 0.071 ... Validation loss: 0.190[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 57.8% ... Training loss: 0.068 ... Validation loss: 0.182[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 57.9% ... Training loss: 0.066 ... Validation loss: 0.180[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 58.0% ... Training loss: 0.076 ... Validation loss: 0.193[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 58.0% ... Training loss: 0.078 ... Validation loss: 0.232[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 58.1% ... Training loss: 0.074 ... Validation loss: 0.153[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 58.2% ... Training loss: 0.070 ... Validation loss: 0.168[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 58.2% ... Training loss: 0.084 ... Validation loss: 0.190[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 58.3% ... Training loss: 0.110 ... Validation loss: 0.241[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 58.4% ... Training loss: 0.077 ... Validation loss: 0.203[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 58.4% ... Training loss: 0.077 ... Validation loss: 0.164[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 58.5% ... Training loss: 0.080 ... Validation loss: 0.214[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 58.6% ... Training loss: 0.104 ... Validation loss: 0.214[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 58.6% ... Training loss: 0.076 ... Validation loss: 0.164[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 58.7% ... Training loss: 0.071 ... Validation loss: 0.193[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 58.8% ... Training loss: 0.065 ... Validation loss: 0.198[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 58.8% ... Training loss: 0.074 ... Validation loss: 0.215[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 58.9% ... Training loss: 0.066 ... Validation loss: 0.177[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 59.0% ... Training loss: 0.065 ... Validation loss: 0.177[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 59.0% ... Training loss: 0.066 ... Validation loss: 0.154[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 59.1% ... Training loss: 0.067 ... Validation loss: 0.159[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 59.2% ... Training loss: 0.106 ... Validation loss: 0.184[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 59.2% ... Training loss: 0.071 ... Validation loss: 0.163[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 59.3% ... Training loss: 0.071 ... Validation loss: 0.201[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 59.4% ... Training loss: 0.080 ... Validation loss: 0.233[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 59.4% ... Training loss: 0.068 ... Validation loss: 0.159[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 59.5% ... Training loss: 0.083 ... Validation loss: 0.167[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 59.6% ... Training loss: 0.076 ... Validation loss: 0.182[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 59.6% ... Training loss: 0.086 ... Validation loss: 0.214[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 59.7% ... Training loss: 0.069 ... Validation loss: 0.168[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 59.8% ... Training loss: 0.111 ... Validation loss: 0.281[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 59.8% ... Training loss: 0.074 ... Validation loss: 0.166[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 59.9% ... Training loss: 0.067 ... Validation loss: 0.171[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 60.0% ... Training loss: 0.073 ... Validation loss: 0.169[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 60.0% ... Training loss: 0.077 ... Validation loss: 0.168[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 60.1% ... Training loss: 0.074 ... Validation loss: 0.223[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 60.2% ... Training loss: 0.072 ... Validation loss: 0.186[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 60.2% ... Training loss: 0.125 ... Validation loss: 0.213[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 60.3% ... Training loss: 0.088 ... Validation loss: 0.165[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 60.4% ... Training loss: 0.065 ... Validation loss: 0.164[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 60.4% ... Training loss: 0.087 ... Validation loss: 0.190[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 60.5% ... Training loss: 0.097 ... Validation loss: 0.163[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 60.6% ... Training loss: 0.075 ... Validation loss: 0.161[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 60.6% ... Training loss: 0.072 ... Validation loss: 0.163[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 60.7% ... Training loss: 0.085 ... Validation loss: 0.205[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 60.8% ... Training loss: 0.109 ... Validation loss: 0.265[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 60.8% ... Training loss: 0.074 ... Validation loss: 0.167[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 60.9% ... Training loss: 0.073 ... Validation loss: 0.167[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 61.0% ... Training loss: 0.076 ... Validation loss: 0.169[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 61.0% ... Training loss: 0.064 ... Validation loss: 0.165[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 61.1% ... Training loss: 0.078 ... Validation loss: 0.178[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 61.2% ... Training loss: 0.085 ... Validation loss: 0.184[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 61.2% ... Training loss: 0.071 ... Validation loss: 0.178[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 61.3% ... Training loss: 0.080 ... Validation loss: 0.177[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 61.4% ... Training loss: 0.079 ... Validation loss: 0.222[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 61.4% ... Training loss: 0.067 ... Validation loss: 0.193[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 61.5% ... Training loss: 0.089 ... Validation loss: 0.232[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 61.6% ... Training loss: 0.069 ... Validation loss: 0.171[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 61.6% ... Training loss: 0.074 ... Validation loss: 0.166[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 61.7% ... Training loss: 0.101 ... Validation loss: 0.190[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 61.8% ... Training loss: 0.074 ... Validation loss: 0.225[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 61.8% ... Training loss: 0.079 ... Validation loss: 0.175[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 61.9% ... Training loss: 0.078 ... Validation loss: 0.156[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 62.0% ... Training loss: 0.096 ... Validation loss: 0.184[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 62.0% ... Training loss: 0.084 ... Validation loss: 0.168[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 62.1% ... Training loss: 0.091 ... Validation loss: 0.214[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 62.2% ... Training loss: 0.073 ... Validation loss: 0.203[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 62.2% ... Training loss: 0.065 ... Validation loss: 0.170[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 62.3% ... Training loss: 0.070 ... Validation loss: 0.156[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 62.4% ... Training loss: 0.067 ... Validation loss: 0.182[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 62.4% ... Training loss: 0.071 ... Validation loss: 0.203[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 62.5% ... Training loss: 0.074 ... Validation loss: 0.180[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 62.6% ... Training loss: 0.080 ... Validation loss: 0.163[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 62.6% ... Training loss: 0.064 ... Validation loss: 0.196[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 62.7% ... Training loss: 0.064 ... Validation loss: 0.180[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 62.8% ... Training loss: 0.076 ... Validation loss: 0.177[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 62.8% ... Training loss: 0.091 ... Validation loss: 0.306[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 62.9% ... Training loss: 0.065 ... Validation loss: 0.196[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 63.0% ... Training loss: 0.076 ... Validation loss: 0.176[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 63.0% ... Training loss: 0.089 ... Validation loss: 0.295[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 63.1% ... Training loss: 0.116 ... Validation loss: 0.272[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 63.2% ... Training loss: 0.080 ... Validation loss: 0.173[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 63.2% ... Training loss: 0.088 ... Validation loss: 0.166[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 63.3% ... Training loss: 0.074 ... Validation loss: 0.219[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 63.4% ... Training loss: 0.083 ... Validation loss: 0.247[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 63.4% ... Training loss: 0.067 ... Validation loss: 0.178[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 63.5% ... Training loss: 0.071 ... Validation loss: 0.186[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 63.6% ... Training loss: 0.098 ... Validation loss: 0.271[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 63.6% ... Training loss: 0.077 ... Validation loss: 0.203[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 63.7% ... Training loss: 0.086 ... Validation loss: 0.297[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 63.8% ... Training loss: 0.083 ... Validation loss: 0.300[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 63.8% ... Training loss: 0.099 ... Validation loss: 0.195[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 63.9% ... Training loss: 0.131 ... Validation loss: 0.224[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 64.0% ... Training loss: 0.078 ... Validation loss: 0.236[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 64.0% ... Training loss: 0.091 ... Validation loss: 0.201[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 64.1% ... Training loss: 0.086 ... Validation loss: 0.220[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 64.2% ... Training loss: 0.080 ... Validation loss: 0.197[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 64.2% ... Training loss: 0.099 ... Validation loss: 0.178[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 64.3% ... Training loss: 0.077 ... Validation loss: 0.163[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 64.4% ... Training loss: 0.087 ... Validation loss: 0.175[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 64.4% ... Training loss: 0.074 ... Validation loss: 0.160[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 64.5% ... Training loss: 0.072 ... Validation loss: 0.183[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 64.6% ... Training loss: 0.073 ... Validation loss: 0.193[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 64.6% ... Training loss: 0.069 ... Validation loss: 0.158[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 64.7% ... Training loss: 0.067 ... Validation loss: 0.175[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 64.8% ... Training loss: 0.076 ... Validation loss: 0.160[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 64.8% ... Training loss: 0.074 ... Validation loss: 0.159[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 64.9% ... Training loss: 0.093 ... Validation loss: 0.199[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 65.0% ... Training loss: 0.079 ... Validation loss: 0.184[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 65.0% ... Training loss: 0.085 ... Validation loss: 0.189[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 65.1% ... Training loss: 0.069 ... Validation loss: 0.190[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 65.2% ... Training loss: 0.095 ... Validation loss: 0.191[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 65.2% ... Training loss: 0.076 ... Validation loss: 0.201[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 65.3% ... Training loss: 0.080 ... Validation loss: 0.201[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 65.4% ... Training loss: 0.074 ... Validation loss: 0.214[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 65.4% ... Training loss: 0.073 ... Validation loss: 0.198[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 65.5% ... Training loss: 0.087 ... Validation loss: 0.169[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 65.6% ... Training loss: 0.074 ... Validation loss: 0.178[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 65.6% ... Training loss: 0.073 ... Validation loss: 0.173[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 65.7% ... Training loss: 0.066 ... Validation loss: 0.171[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 65.8% ... Training loss: 0.097 ... Validation loss: 0.177[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 65.8% ... Training loss: 0.082 ... Validation loss: 0.198[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 65.9% ... Training loss: 0.081 ... Validation loss: 0.254[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 66.0% ... Training loss: 0.079 ... Validation loss: 0.159[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 66.0% ... Training loss: 0.074 ... Validation loss: 0.167[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 66.1% ... Training loss: 0.093 ... Validation loss: 0.204[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 66.2% ... Training loss: 0.086 ... Validation loss: 0.149[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 66.2% ... Training loss: 0.071 ... Validation loss: 0.214[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 66.3% ... Training loss: 0.069 ... Validation loss: 0.204[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 66.4% ... Training loss: 0.088 ... Validation loss: 0.182[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 66.4% ... Training loss: 0.079 ... Validation loss: 0.187[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 66.5% ... Training loss: 0.074 ... Validation loss: 0.186[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 66.6% ... Training loss: 0.072 ... Validation loss: 0.167[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 66.6% ... Training loss: 0.077 ... Validation loss: 0.199[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 66.7% ... Training loss: 0.070 ... Validation loss: 0.189[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 66.8% ... Training loss: 0.104 ... Validation loss: 0.235[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 66.8% ... Training loss: 0.074 ... Validation loss: 0.190[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 66.9% ... Training loss: 0.075 ... Validation loss: 0.164[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 67.0% ... Training loss: 0.067 ... Validation loss: 0.187[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 67.0% ... Training loss: 0.067 ... Validation loss: 0.200[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 67.1% ... Training loss: 0.085 ... Validation loss: 0.230[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 67.2% ... Training loss: 0.093 ... Validation loss: 0.165[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 67.2% ... Training loss: 0.068 ... Validation loss: 0.222[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 67.3% ... Training loss: 0.071 ... Validation loss: 0.182[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 67.4% ... Training loss: 0.071 ... Validation loss: 0.168[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 67.4% ... Training loss: 0.076 ... Validation loss: 0.171[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 67.5% ... Training loss: 0.072 ... Validation loss: 0.166[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 67.6% ... Training loss: 0.097 ... Validation loss: 0.171[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 67.6% ... Training loss: 0.067 ... Validation loss: 0.147[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 67.7% ... Training loss: 0.076 ... Validation loss: 0.171[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 67.8% ... Training loss: 0.069 ... Validation loss: 0.183[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 67.8% ... Training loss: 0.072 ... Validation loss: 0.203[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 67.9% ... Training loss: 0.099 ... Validation loss: 0.295[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 68.0% ... Training loss: 0.085 ... Validation loss: 0.151[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 68.0% ... Training loss: 0.074 ... Validation loss: 0.153[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 68.1% ... Training loss: 0.077 ... Validation loss: 0.170[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 68.2% ... Training loss: 0.074 ... Validation loss: 0.170[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 68.2% ... Training loss: 0.082 ... Validation loss: 0.162[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 68.3% ... Training loss: 0.098 ... Validation loss: 0.221[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 68.4% ... Training loss: 0.076 ... Validation loss: 0.194[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 68.4% ... Training loss: 0.084 ... Validation loss: 0.198[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 68.5% ... Training loss: 0.101 ... Validation loss: 0.183[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 68.6% ... Training loss: 0.099 ... Validation loss: 0.187[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 68.6% ... Training loss: 0.079 ... Validation loss: 0.164[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 68.7% ... Training loss: 0.083 ... Validation loss: 0.209[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 68.8% ... Training loss: 0.075 ... Validation loss: 0.213[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 68.8% ... Training loss: 0.080 ... Validation loss: 0.204[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 68.9% ... Training loss: 0.074 ... Validation loss: 0.164[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 69.0% ... Training loss: 0.108 ... Validation loss: 0.203[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 69.0% ... Training loss: 0.071 ... Validation loss: 0.175[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 69.1% ... Training loss: 0.069 ... Validation loss: 0.150[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 69.2% ... Training loss: 0.080 ... Validation loss: 0.162[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 69.2% ... Training loss: 0.074 ... Validation loss: 0.194[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 69.3% ... Training loss: 0.073 ... Validation loss: 0.170[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 69.4% ... Training loss: 0.095 ... Validation loss: 0.184[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 69.4% ... Training loss: 0.064 ... Validation loss: 0.166[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 69.5% ... Training loss: 0.061 ... Validation loss: 0.156[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 69.6% ... Training loss: 0.068 ... Validation loss: 0.179[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 69.6% ... Training loss: 0.063 ... Validation loss: 0.154[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 69.7% ... Training loss: 0.078 ... Validation loss: 0.154[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 69.8% ... Training loss: 0.083 ... Validation loss: 0.195[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 69.8% ... Training loss: 0.064 ... Validation loss: 0.151[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 69.9% ... Training loss: 0.080 ... Validation loss: 0.151[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 70.0% ... Training loss: 0.094 ... Validation loss: 0.192[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 70.0% ... Training loss: 0.083 ... Validation loss: 0.153[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 70.1% ... Training loss: 0.074 ... Validation loss: 0.178[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 70.2% ... Training loss: 0.067 ... Validation loss: 0.154[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 70.2% ... Training loss: 0.077 ... Validation loss: 0.154[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 70.3% ... Training loss: 0.072 ... Validation loss: 0.157[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 70.4% ... Training loss: 0.073 ... Validation loss: 0.154[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 70.4% ... Training loss: 0.066 ... Validation loss: 0.164[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 70.5% ... Training loss: 0.076 ... Validation loss: 0.176[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 70.6% ... Training loss: 0.064 ... Validation loss: 0.184[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 70.6% ... Training loss: 0.087 ... Validation loss: 0.176[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 70.7% ... Training loss: 0.077 ... Validation loss: 0.191[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 70.8% ... Training loss: 0.093 ... Validation loss: 0.247[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 70.8% ... Training loss: 0.069 ... Validation loss: 0.163[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 70.9% ... Training loss: 0.079 ... Validation loss: 0.157[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 71.0% ... Training loss: 0.082 ... Validation loss: 0.221[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 71.0% ... Training loss: 0.072 ... Validation loss: 0.188[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 71.1% ... Training loss: 0.065 ... Validation loss: 0.182[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 71.2% ... Training loss: 0.078 ... Validation loss: 0.171[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 71.2% ... Training loss: 0.077 ... Validation loss: 0.243[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 71.3% ... Training loss: 0.071 ... Validation loss: 0.201[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 71.4% ... Training loss: 0.078 ... Validation loss: 0.166[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 71.4% ... Training loss: 0.110 ... Validation loss: 0.189[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 71.5% ... Training loss: 0.080 ... Validation loss: 0.189[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 71.6% ... Training loss: 0.062 ... Validation loss: 0.165[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 71.6% ... Training loss: 0.095 ... Validation loss: 0.213[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 71.7% ... Training loss: 0.064 ... Validation loss: 0.155[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 71.8% ... Training loss: 0.065 ... Validation loss: 0.183[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 71.8% ... Training loss: 0.070 ... Validation loss: 0.167[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 71.9% ... Training loss: 0.088 ... Validation loss: 0.201[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 72.0% ... Training loss: 0.072 ... Validation loss: 0.158[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 72.0% ... Training loss: 0.091 ... Validation loss: 0.194[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 72.1% ... Training loss: 0.080 ... Validation loss: 0.184[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 72.2% ... Training loss: 0.076 ... Validation loss: 0.193[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 72.2% ... Training loss: 0.062 ... Validation loss: 0.156[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 72.3% ... Training loss: 0.076 ... Validation loss: 0.148[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 72.4% ... Training loss: 0.101 ... Validation loss: 0.176[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 72.4% ... Training loss: 0.071 ... Validation loss: 0.160[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 72.5% ... Training loss: 0.077 ... Validation loss: 0.160[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 72.6% ... Training loss: 0.075 ... Validation loss: 0.205[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 72.6% ... Training loss: 0.063 ... Validation loss: 0.198[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 72.7% ... Training loss: 0.096 ... Validation loss: 0.156[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 72.8% ... Training loss: 0.079 ... Validation loss: 0.268[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 72.8% ... Training loss: 0.085 ... Validation loss: 0.167[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 72.9% ... Training loss: 0.081 ... Validation loss: 0.209[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 73.0% ... Training loss: 0.076 ... Validation loss: 0.156[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 73.0% ... Training loss: 0.076 ... Validation loss: 0.155[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 73.1% ... Training loss: 0.076 ... Validation loss: 0.168[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 73.2% ... Training loss: 0.086 ... Validation loss: 0.208[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 73.2% ... Training loss: 0.072 ... Validation loss: 0.148[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 73.3% ... Training loss: 0.074 ... Validation loss: 0.158[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 73.4% ... Training loss: 0.076 ... Validation loss: 0.188[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 73.4% ... Training loss: 0.069 ... Validation loss: 0.153[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 73.5% ... Training loss: 0.063 ... Validation loss: 0.160[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 73.6% ... Training loss: 0.068 ... Validation loss: 0.153[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 73.6% ... Training loss: 0.070 ... Validation loss: 0.209[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 73.7% ... Training loss: 0.076 ... Validation loss: 0.155[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 73.8% ... Training loss: 0.067 ... Validation loss: 0.201[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 73.8% ... Training loss: 0.070 ... Validation loss: 0.179[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 73.9% ... Training loss: 0.070 ... Validation loss: 0.184[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 74.0% ... Training loss: 0.082 ... Validation loss: 0.210[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 74.0% ... Training loss: 0.076 ... Validation loss: 0.194[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 74.1% ... Training loss: 0.073 ... Validation loss: 0.162[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 74.2% ... Training loss: 0.080 ... Validation loss: 0.182[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 74.2% ... Training loss: 0.067 ... Validation loss: 0.179[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 74.3% ... Training loss: 0.070 ... Validation loss: 0.167[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 74.4% ... Training loss: 0.068 ... Validation loss: 0.157[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 74.4% ... Training loss: 0.071 ... Validation loss: 0.177[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 74.5% ... Training loss: 0.091 ... Validation loss: 0.205[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 74.6% ... Training loss: 0.109 ... Validation loss: 0.251[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 74.6% ... Training loss: 0.112 ... Validation loss: 0.252[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 74.7% ... Training loss: 0.076 ... Validation loss: 0.171[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 74.8% ... Training loss: 0.072 ... Validation loss: 0.162[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 74.8% ... Training loss: 0.075 ... Validation loss: 0.167[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 74.9% ... Training loss: 0.078 ... Validation loss: 0.165[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 75.0% ... Training loss: 0.088 ... Validation loss: 0.215[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 75.0% ... Training loss: 0.073 ... Validation loss: 0.167[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 75.1% ... Training loss: 0.098 ... Validation loss: 0.180[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 75.2% ... Training loss: 0.072 ... Validation loss: 0.204[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 75.2% ... Training loss: 0.067 ... Validation loss: 0.194[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 75.3% ... Training loss: 0.069 ... Validation loss: 0.147[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 75.4% ... Training loss: 0.097 ... Validation loss: 0.166[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 75.4% ... Training loss: 0.068 ... Validation loss: 0.176[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 75.5% ... Training loss: 0.068 ... Validation loss: 0.161[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 75.6% ... Training loss: 0.067 ... Validation loss: 0.164[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 75.6% ... Training loss: 0.068 ... Validation loss: 0.155[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 75.7% ... Training loss: 0.065 ... Validation loss: 0.171[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 75.8% ... Training loss: 0.068 ... Validation loss: 0.185[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 75.8% ... Training loss: 0.067 ... Validation loss: 0.156[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 75.9% ... Training loss: 0.074 ... Validation loss: 0.171[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 76.0% ... Training loss: 0.059 ... Validation loss: 0.162[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 76.0% ... Training loss: 0.069 ... Validation loss: 0.189[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 76.1% ... Training loss: 0.072 ... Validation loss: 0.178[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 76.2% ... Training loss: 0.091 ... Validation loss: 0.219[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 76.2% ... Training loss: 0.100 ... Validation loss: 0.183[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 76.3% ... Training loss: 0.064 ... Validation loss: 0.178[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 76.4% ... Training loss: 0.063 ... Validation loss: 0.155[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 76.4% ... Training loss: 0.068 ... Validation loss: 0.185[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 76.5% ... Training loss: 0.072 ... Validation loss: 0.182[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 76.6% ... Training loss: 0.064 ... Validation loss: 0.163[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 76.6% ... Training loss: 0.066 ... Validation loss: 0.162[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 76.7% ... Training loss: 0.065 ... Validation loss: 0.187[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 76.8% ... Training loss: 0.073 ... Validation loss: 0.185[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 76.8% ... Training loss: 0.066 ... Validation loss: 0.174[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 76.9% ... Training loss: 0.094 ... Validation loss: 0.283[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 77.0% ... Training loss: 0.080 ... Validation loss: 0.248[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 77.0% ... Training loss: 0.069 ... Validation loss: 0.175[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 77.1% ... Training loss: 0.070 ... Validation loss: 0.189[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 77.2% ... Training loss: 0.077 ... Validation loss: 0.232[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 77.2% ... Training loss: 0.064 ... Validation loss: 0.168[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 77.3% ... Training loss: 0.077 ... Validation loss: 0.154[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 77.4% ... Training loss: 0.066 ... Validation loss: 0.162[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 77.4% ... Training loss: 0.079 ... Validation loss: 0.168[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 77.5% ... Training loss: 0.070 ... Validation loss: 0.169[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 77.6% ... Training loss: 0.068 ... Validation loss: 0.162[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 77.6% ... Training loss: 0.073 ... Validation loss: 0.167[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 77.7% ... Training loss: 0.071 ... Validation loss: 0.164[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 77.8% ... Training loss: 0.093 ... Validation loss: 0.200[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 77.8% ... Training loss: 0.065 ... Validation loss: 0.166[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 77.9% ... Training loss: 0.064 ... Validation loss: 0.168[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 78.0% ... Training loss: 0.100 ... Validation loss: 0.165[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 78.0% ... Training loss: 0.076 ... Validation loss: 0.159[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 78.1% ... Training loss: 0.076 ... Validation loss: 0.155[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 78.2% ... Training loss: 0.076 ... Validation loss: 0.199[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 78.2% ... Training loss: 0.083 ... Validation loss: 0.173[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 78.3% ... Training loss: 0.074 ... Validation loss: 0.237[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 78.4% ... Training loss: 0.079 ... Validation loss: 0.227[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 78.4% ... Training loss: 0.077 ... Validation loss: 0.266[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 78.5% ... Training loss: 0.090 ... Validation loss: 0.176[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 78.6% ... Training loss: 0.091 ... Validation loss: 0.246[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 78.6% ... Training loss: 0.067 ... Validation loss: 0.156[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 78.7% ... Training loss: 0.083 ... Validation loss: 0.176[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 78.8% ... Training loss: 0.077 ... Validation loss: 0.216[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 78.8% ... Training loss: 0.077 ... Validation loss: 0.174[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 78.9% ... Training loss: 0.067 ... Validation loss: 0.194[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 79.0% ... Training loss: 0.074 ... Validation loss: 0.166[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 79.0% ... Training loss: 0.084 ... Validation loss: 0.199[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 79.1% ... Training loss: 0.086 ... Validation loss: 0.210[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 79.2% ... Training loss: 0.065 ... Validation loss: 0.170[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 79.2% ... Training loss: 0.096 ... Validation loss: 0.212[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 79.3% ... Training loss: 0.066 ... Validation loss: 0.160[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 79.4% ... Training loss: 0.075 ... Validation loss: 0.161[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 79.4% ... Training loss: 0.096 ... Validation loss: 0.172[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 79.5% ... Training loss: 0.092 ... Validation loss: 0.181[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 79.6% ... Training loss: 0.068 ... Validation loss: 0.184[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 79.6% ... Training loss: 0.070 ... Validation loss: 0.202[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 79.7% ... Training loss: 0.078 ... Validation loss: 0.259[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 79.8% ... Training loss: 0.079 ... Validation loss: 0.210[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 79.8% ... Training loss: 0.076 ... Validation loss: 0.186[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 79.9% ... Training loss: 0.092 ... Validation loss: 0.260[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 80.0% ... Training loss: 0.075 ... Validation loss: 0.215[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 80.0% ... Training loss: 0.074 ... Validation loss: 0.202[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 80.1% ... Training loss: 0.092 ... Validation loss: 0.192[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 80.2% ... Training loss: 0.077 ... Validation loss: 0.191[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 80.2% ... Training loss: 0.062 ... Validation loss: 0.156[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 80.3% ... Training loss: 0.089 ... Validation loss: 0.205[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 80.4% ... Training loss: 0.075 ... Validation loss: 0.187[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 80.4% ... Training loss: 0.103 ... Validation loss: 0.218[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 80.5% ... Training loss: 0.077 ... Validation loss: 0.169[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 80.6% ... Training loss: 0.081 ... Validation loss: 0.151[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 80.6% ... Training loss: 0.066 ... Validation loss: 0.156[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 80.7% ... Training loss: 0.072 ... Validation loss: 0.273[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 80.8% ... Training loss: 0.088 ... Validation loss: 0.187[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 80.8% ... Training loss: 0.087 ... Validation loss: 0.226[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 80.9% ... Training loss: 0.078 ... Validation loss: 0.198[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 81.0% ... Training loss: 0.088 ... Validation loss: 0.174[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 81.0% ... Training loss: 0.072 ... Validation loss: 0.157[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 81.1% ... Training loss: 0.073 ... Validation loss: 0.154[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 81.2% ... Training loss: 0.068 ... Validation loss: 0.179[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 81.2% ... Training loss: 0.065 ... Validation loss: 0.179[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 81.3% ... Training loss: 0.065 ... Validation loss: 0.178[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 81.4% ... Training loss: 0.070 ... Validation loss: 0.156[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 81.4% ... Training loss: 0.071 ... Validation loss: 0.163[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 81.5% ... Training loss: 0.068 ... Validation loss: 0.183[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 81.6% ... Training loss: 0.070 ... Validation loss: 0.202[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 81.6% ... Training loss: 0.077 ... Validation loss: 0.175[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 81.7% ... Training loss: 0.079 ... Validation loss: 0.181[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 81.8% ... Training loss: 0.082 ... Validation loss: 0.188[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 81.8% ... Training loss: 0.084 ... Validation loss: 0.218[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 81.9% ... Training loss: 0.062 ... Validation loss: 0.177[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 82.0% ... Training loss: 0.087 ... Validation loss: 0.189[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 82.0% ... Training loss: 0.074 ... Validation loss: 0.170[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 82.1% ... Training loss: 0.076 ... Validation loss: 0.187[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 82.2% ... Training loss: 0.087 ... Validation loss: 0.172[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 82.2% ... Training loss: 0.078 ... Validation loss: 0.228[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 82.3% ... Training loss: 0.088 ... Validation loss: 0.183[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 82.4% ... Training loss: 0.089 ... Validation loss: 0.290[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 82.4% ... Training loss: 0.071 ... Validation loss: 0.196[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 82.5% ... Training loss: 0.101 ... Validation loss: 0.179[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 82.6% ... Training loss: 0.067 ... Validation loss: 0.225[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 82.6% ... Training loss: 0.066 ... Validation loss: 0.178[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 82.7% ... Training loss: 0.068 ... Validation loss: 0.215[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 82.8% ... Training loss: 0.111 ... Validation loss: 0.181[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 82.8% ... Training loss: 0.065 ... Validation loss: 0.216[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 82.9% ... Training loss: 0.086 ... Validation loss: 0.200[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 83.0% ... Training loss: 0.076 ... Validation loss: 0.174[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 83.0% ... Training loss: 0.102 ... Validation loss: 0.205[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 83.1% ... Training loss: 0.080 ... Validation loss: 0.228[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 83.2% ... Training loss: 0.078 ... Validation loss: 0.223[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 83.2% ... Training loss: 0.085 ... Validation loss: 0.233[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 83.3% ... Training loss: 0.073 ... Validation loss: 0.166[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 83.4% ... Training loss: 0.104 ... Validation loss: 0.240[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 83.4% ... Training loss: 0.072 ... Validation loss: 0.194[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 83.5% ... Training loss: 0.097 ... Validation loss: 0.162[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 83.6% ... Training loss: 0.086 ... Validation loss: 0.167[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 83.6% ... Training loss: 0.080 ... Validation loss: 0.187[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 83.7% ... Training loss: 0.074 ... Validation loss: 0.187[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 83.8% ... Training loss: 0.083 ... Validation loss: 0.181[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 83.8% ... Training loss: 0.089 ... Validation loss: 0.204[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 83.9% ... Training loss: 0.077 ... Validation loss: 0.156[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 84.0% ... Training loss: 0.069 ... Validation loss: 0.148[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 84.0% ... Training loss: 0.076 ... Validation loss: 0.162[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 84.1% ... Training loss: 0.096 ... Validation loss: 0.197[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 84.2% ... Training loss: 0.074 ... Validation loss: 0.156[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 84.2% ... Training loss: 0.094 ... Validation loss: 0.165[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 84.3% ... Training loss: 0.069 ... Validation loss: 0.155[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 84.4% ... Training loss: 0.073 ... Validation loss: 0.161[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 84.4% ... Training loss: 0.068 ... Validation loss: 0.159[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 84.5% ... Training loss: 0.072 ... Validation loss: 0.155[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 84.6% ... Training loss: 0.073 ... Validation loss: 0.196[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 84.6% ... Training loss: 0.074 ... Validation loss: 0.211[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 84.7% ... Training loss: 0.072 ... Validation loss: 0.189[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 84.8% ... Training loss: 0.070 ... Validation loss: 0.179[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 84.8% ... Training loss: 0.080 ... Validation loss: 0.170[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 84.9% ... Training loss: 0.078 ... Validation loss: 0.185[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 85.0% ... Training loss: 0.073 ... Validation loss: 0.171[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 85.0% ... Training loss: 0.156 ... Validation loss: 0.227[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 85.1% ... Training loss: 0.082 ... Validation loss: 0.212[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 85.2% ... Training loss: 0.069 ... Validation loss: 0.207[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 85.2% ... Training loss: 0.082 ... Validation loss: 0.242[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 85.3% ... Training loss: 0.191 ... Validation loss: 0.275[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 85.4% ... Training loss: 0.080 ... Validation loss: 0.190[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 85.4% ... Training loss: 0.074 ... Validation loss: 0.156[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 85.5% ... Training loss: 0.073 ... Validation loss: 0.184[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 85.6% ... Training loss: 0.066 ... Validation loss: 0.204[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 85.6% ... Training loss: 0.074 ... Validation loss: 0.221[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 85.7% ... Training loss: 0.067 ... Validation loss: 0.199[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 85.8% ... Training loss: 0.069 ... Validation loss: 0.190[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 85.8% ... Training loss: 0.072 ... Validation loss: 0.197[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 85.9% ... Training loss: 0.083 ... Validation loss: 0.152[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 86.0% ... Training loss: 0.067 ... Validation loss: 0.193[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 86.0% ... Training loss: 0.082 ... Validation loss: 0.247[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 86.1% ... Training loss: 0.084 ... Validation loss: 0.228[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 86.2% ... Training loss: 0.073 ... Validation loss: 0.177[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 86.2% ... Training loss: 0.073 ... Validation loss: 0.229[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 86.3% ... Training loss: 0.077 ... Validation loss: 0.197[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 86.4% ... Training loss: 0.101 ... Validation loss: 0.289[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 86.4% ... Training loss: 0.066 ... Validation loss: 0.182[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 86.5% ... Training loss: 0.084 ... Validation loss: 0.303[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 86.6% ... Training loss: 0.080 ... Validation loss: 0.192[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 86.6% ... Training loss: 0.102 ... Validation loss: 0.302[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 86.7% ... Training loss: 0.079 ... Validation loss: 0.234[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 86.8% ... Training loss: 0.075 ... Validation loss: 0.199[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 86.8% ... Training loss: 0.073 ... Validation loss: 0.201[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 86.9% ... Training loss: 0.080 ... Validation loss: 0.245[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 87.0% ... Training loss: 0.069 ... Validation loss: 0.214[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 87.0% ... Training loss: 0.083 ... Validation loss: 0.203[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 87.1% ... Training loss: 0.076 ... Validation loss: 0.246[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 87.2% ... Training loss: 0.078 ... Validation loss: 0.199[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 87.2% ... Training loss: 0.123 ... Validation loss: 0.214[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 87.3% ... Training loss: 0.072 ... Validation loss: 0.183[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 87.4% ... Training loss: 0.076 ... Validation loss: 0.216[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 87.4% ... Training loss: 0.068 ... Validation loss: 0.183[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 87.5% ... Training loss: 0.067 ... Validation loss: 0.215[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 87.6% ... Training loss: 0.067 ... Validation loss: 0.181[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 87.6% ... Training loss: 0.061 ... Validation loss: 0.187[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 87.7% ... Training loss: 0.067 ... Validation loss: 0.203[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 87.8% ... Training loss: 0.067 ... Validation loss: 0.175[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 87.8% ... Training loss: 0.064 ... Validation loss: 0.177[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 87.9% ... Training loss: 0.088 ... Validation loss: 0.200[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 88.0% ... Training loss: 0.076 ... Validation loss: 0.245[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 88.0% ... Training loss: 0.075 ... Validation loss: 0.229[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 88.1% ... Training loss: 0.076 ... Validation loss: 0.212[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 88.2% ... Training loss: 0.074 ... Validation loss: 0.252[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 88.2% ... Training loss: 0.080 ... Validation loss: 0.265[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 88.3% ... Training loss: 0.075 ... Validation loss: 0.213[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 88.4% ... Training loss: 0.088 ... Validation loss: 0.301[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 88.4% ... Training loss: 0.063 ... Validation loss: 0.201[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 88.5% ... Training loss: 0.072 ... Validation loss: 0.209[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 88.6% ... Training loss: 0.081 ... Validation loss: 0.215[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 88.6% ... Training loss: 0.066 ... Validation loss: 0.191[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 88.7% ... Training loss: 0.070 ... Validation loss: 0.215[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 88.8% ... Training loss: 0.068 ... Validation loss: 0.219[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 88.8% ... Training loss: 0.072 ... Validation loss: 0.227[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 88.9% ... Training loss: 0.079 ... Validation loss: 0.234[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 89.0% ... Training loss: 0.078 ... Validation loss: 0.171[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 89.0% ... Training loss: 0.079 ... Validation loss: 0.149[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 89.1% ... Training loss: 0.072 ... Validation loss: 0.152[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 89.2% ... Training loss: 0.064 ... Validation loss: 0.177[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 89.2% ... Training loss: 0.071 ... Validation loss: 0.210[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 89.3% ... Training loss: 0.085 ... Validation loss: 0.178[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 89.4% ... Training loss: 0.079 ... Validation loss: 0.168[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 89.4% ... Training loss: 0.092 ... Validation loss: 0.245[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 89.5% ... Training loss: 0.070 ... Validation loss: 0.237[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 89.6% ... Training loss: 0.080 ... Validation loss: 0.287[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 89.6% ... Training loss: 0.065 ... Validation loss: 0.174[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 89.7% ... Training loss: 0.061 ... Validation loss: 0.181[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 89.8% ... Training loss: 0.091 ... Validation loss: 0.190[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 89.8% ... Training loss: 0.076 ... Validation loss: 0.215[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 89.9% ... Training loss: 0.074 ... Validation loss: 0.222[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 90.0% ... Training loss: 0.065 ... Validation loss: 0.204[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 90.0% ... Training loss: 0.072 ... Validation loss: 0.184[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 90.1% ... Training loss: 0.071 ... Validation loss: 0.177[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 90.2% ... Training loss: 0.080 ... Validation loss: 0.244[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 90.2% ... Training loss: 0.066 ... Validation loss: 0.183[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 90.3% ... Training loss: 0.065 ... Validation loss: 0.167[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 90.4% ... Training loss: 0.061 ... Validation loss: 0.185[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 90.4% ... Training loss: 0.080 ... Validation loss: 0.169[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 90.5% ... Training loss: 0.077 ... Validation loss: 0.177[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 90.6% ... Training loss: 0.085 ... Validation loss: 0.190[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 90.6% ... Training loss: 0.109 ... Validation loss: 0.210[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 90.7% ... Training loss: 0.085 ... Validation loss: 0.177[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 90.8% ... Training loss: 0.070 ... Validation loss: 0.147[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 90.8% ... Training loss: 0.061 ... Validation loss: 0.155[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 90.9% ... Training loss: 0.069 ... Validation loss: 0.217[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 91.0% ... Training loss: 0.070 ... Validation loss: 0.226[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 91.0% ... Training loss: 0.087 ... Validation loss: 0.167[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 91.1% ... Training loss: 0.068 ... Validation loss: 0.164[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 91.2% ... Training loss: 0.064 ... Validation loss: 0.167[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 91.2% ... Training loss: 0.072 ... Validation loss: 0.176[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 91.3% ... Training loss: 0.072 ... Validation loss: 0.156[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 91.4% ... Training loss: 0.070 ... Validation loss: 0.170[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 91.4% ... Training loss: 0.068 ... Validation loss: 0.167[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 91.5% ... Training loss: 0.065 ... Validation loss: 0.177[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 91.6% ... Training loss: 0.199 ... Validation loss: 0.379[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 91.6% ... Training loss: 0.080 ... Validation loss: 0.169[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 91.7% ... Training loss: 0.062 ... Validation loss: 0.168[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 91.8% ... Training loss: 0.071 ... Validation loss: 0.189[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 91.8% ... Training loss: 0.078 ... Validation loss: 0.182[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 91.9% ... Training loss: 0.075 ... Validation loss: 0.171[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 92.0% ... Training loss: 0.072 ... Validation loss: 0.182[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 92.0% ... Training loss: 0.069 ... Validation loss: 0.178[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 92.1% ... Training loss: 0.079 ... Validation loss: 0.162[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 92.2% ... Training loss: 0.071 ... Validation loss: 0.186[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 92.2% ... Training loss: 0.078 ... Validation loss: 0.194[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 92.3% ... Training loss: 0.066 ... Validation loss: 0.183[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 92.4% ... Training loss: 0.064 ... Validation loss: 0.173[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 92.4% ... Training loss: 0.100 ... Validation loss: 0.216[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 92.5% ... Training loss: 0.083 ... Validation loss: 0.189[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 92.6% ... Training loss: 0.063 ... Validation loss: 0.164[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 92.6% ... Training loss: 0.061 ... Validation loss: 0.187[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 92.7% ... Training loss: 0.074 ... Validation loss: 0.166[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 92.8% ... Training loss: 0.072 ... Validation loss: 0.194[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 92.8% ... Training loss: 0.092 ... Validation loss: 0.202[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 92.9% ... Training loss: 0.082 ... Validation loss: 0.182[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 93.0% ... Training loss: 0.084 ... Validation loss: 0.185[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 93.0% ... Training loss: 0.073 ... Validation loss: 0.168[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 93.1% ... Training loss: 0.076 ... Validation loss: 0.157[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 93.2% ... Training loss: 0.085 ... Validation loss: 0.186[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 93.2% ... Training loss: 0.071 ... Validation loss: 0.167[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 93.3% ... Training loss: 0.065 ... Validation loss: 0.166[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 93.4% ... Training loss: 0.067 ... Validation loss: 0.200[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 93.4% ... Training loss: 0.091 ... Validation loss: 0.214[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 93.5% ... Training loss: 0.065 ... Validation loss: 0.169[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 93.6% ... Training loss: 0.073 ... Validation loss: 0.198[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 93.6% ... Training loss: 0.059 ... Validation loss: 0.166[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 93.7% ... Training loss: 0.076 ... Validation loss: 0.175[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 93.8% ... Training loss: 0.073 ... Validation loss: 0.166[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 93.8% ... Training loss: 0.073 ... Validation loss: 0.174[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 93.9% ... Training loss: 0.071 ... Validation loss: 0.161[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 94.0% ... Training loss: 0.069 ... Validation loss: 0.191[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 94.0% ... Training loss: 0.069 ... Validation loss: 0.181[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 94.1% ... Training loss: 0.084 ... Validation loss: 0.198[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 94.2% ... Training loss: 0.072 ... Validation loss: 0.163[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 94.2% ... Training loss: 0.096 ... Validation loss: 0.182[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 94.3% ... Training loss: 0.089 ... Validation loss: 0.174[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 94.4% ... Training loss: 0.074 ... Validation loss: 0.178[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 94.4% ... Training loss: 0.080 ... Validation loss: 0.184[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 94.5% ... Training loss: 0.087 ... Validation loss: 0.181[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 94.6% ... Training loss: 0.070 ... Validation loss: 0.176[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 94.6% ... Training loss: 0.072 ... Validation loss: 0.156[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 94.7% ... Training loss: 0.110 ... Validation loss: 0.187[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 94.8% ... Training loss: 0.071 ... Validation loss: 0.150[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 94.8% ... Training loss: 0.131 ... Validation loss: 0.206[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 94.9% ... Training loss: 0.066 ... Validation loss: 0.151[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 95.0% ... Training loss: 0.075 ... Validation loss: 0.165[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 95.0% ... Training loss: 0.069 ... Validation loss: 0.159[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 95.1% ... Training loss: 0.067 ... Validation loss: 0.176[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 95.2% ... Training loss: 0.065 ... Validation loss: 0.173[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 95.2% ... Training loss: 0.071 ... Validation loss: 0.173[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 95.3% ... Training loss: 0.071 ... Validation loss: 0.177[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 95.4% ... Training loss: 0.075 ... Validation loss: 0.176[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 95.4% ... Training loss: 0.072 ... Validation loss: 0.169[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 95.5% ... Training loss: 0.075 ... Validation loss: 0.160[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 95.6% ... Training loss: 0.063 ... Validation loss: 0.177[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 95.6% ... Training loss: 0.065 ... Validation loss: 0.165[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 95.7% ... Training loss: 0.091 ... Validation loss: 0.171[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 95.8% ... Training loss: 0.102 ... Validation loss: 0.197[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 95.8% ... Training loss: 0.072 ... Validation loss: 0.169[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 95.9% ... Training loss: 0.061 ... Validation loss: 0.158[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 96.0% ... Training loss: 0.070 ... Validation loss: 0.188[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 96.0% ... Training loss: 0.079 ... Validation loss: 0.237[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 96.1% ... Training loss: 0.091 ... Validation loss: 0.223[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 96.2% ... Training loss: 0.076 ... Validation loss: 0.181[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 96.2% ... Training loss: 0.072 ... Validation loss: 0.180[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 96.3% ... Training loss: 0.063 ... Validation loss: 0.180[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 96.4% ... Training loss: 0.063 ... Validation loss: 0.196[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 96.4% ... Training loss: 0.060 ... Validation loss: 0.170[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 96.5% ... Training loss: 0.063 ... Validation loss: 0.192[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 96.6% ... Training loss: 0.070 ... Validation loss: 0.165[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 96.6% ... Training loss: 0.068 ... Validation loss: 0.181[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 96.7% ... Training loss: 0.088 ... Validation loss: 0.218[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 96.8% ... Training loss: 0.067 ... Validation loss: 0.180[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 96.8% ... Training loss: 0.084 ... Validation loss: 0.163[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 96.9% ... Training loss: 0.071 ... Validation loss: 0.188[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 97.0% ... Training loss: 0.094 ... Validation loss: 0.207[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 97.0% ... Training loss: 0.073 ... Validation loss: 0.185[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 97.1% ... Training loss: 0.067 ... Validation loss: 0.174[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 97.2% ... Training loss: 0.067 ... Validation loss: 0.163[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 97.2% ... Training loss: 0.108 ... Validation loss: 0.207[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 97.3% ... Training loss: 0.084 ... Validation loss: 0.213[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 97.4% ... Training loss: 0.080 ... Validation loss: 0.177[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 97.4% ... Training loss: 0.076 ... Validation loss: 0.199[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 97.5% ... Training loss: 0.071 ... Validation loss: 0.188[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 97.6% ... Training loss: 0.079 ... Validation loss: 0.157[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 97.6% ... Training loss: 0.063 ... Validation loss: 0.163[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 97.7% ... Training loss: 0.063 ... Validation loss: 0.177[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 97.8% ... Training loss: 0.062 ... Validation loss: 0.159[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 97.8% ... Training loss: 0.070 ... Validation loss: 0.152[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 97.9% ... Training loss: 0.066 ... Validation loss: 0.179[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 98.0% ... Training loss: 0.082 ... Validation loss: 0.163[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 98.0% ... Training loss: 0.077 ... Validation loss: 0.156[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 98.1% ... Training loss: 0.068 ... Validation loss: 0.210[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 98.2% ... Training loss: 0.082 ... Validation loss: 0.181[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 98.2% ... Training loss: 0.067 ... Validation loss: 0.216[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 98.3% ... Training loss: 0.066 ... Validation loss: 0.201[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 98.4% ... Training loss: 0.078 ... Validation loss: 0.177[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 98.4% ... Training loss: 0.087 ... Validation loss: 0.239[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 98.5% ... Training loss: 0.099 ... Validation loss: 0.272[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 98.6% ... Training loss: 0.079 ... Validation loss: 0.252[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 98.6% ... Training loss: 0.071 ... Validation loss: 0.189[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 98.7% ... Training loss: 0.069 ... Validation loss: 0.182[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 98.8% ... Training loss: 0.080 ... Validation loss: 0.182[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 98.8% ... Training loss: 0.074 ... Validation loss: 0.163[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 98.9% ... Training loss: 0.065 ... Validation loss: 0.154[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 99.0% ... Training loss: 0.104 ... Validation loss: 0.183[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 99.0% ... Training loss: 0.076 ... Validation loss: 0.191[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 99.1% ... Training loss: 0.077 ... Validation loss: 0.158[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 99.2% ... Training loss: 0.094 ... Validation loss: 0.166[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 99.2% ... Training loss: 0.080 ... Validation loss: 0.189[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 99.3% ... Training loss: 0.084 ... Validation loss: 0.165[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 99.4% ... Training loss: 0.086 ... Validation loss: 0.196[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 99.4% ... Training loss: 0.067 ... Validation loss: 0.192[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 99.5% ... Training loss: 0.069 ... Validation loss: 0.163[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 99.6% ... Training loss: 0.161 ... Validation loss: 0.322[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 99.6% ... Training loss: 0.069 ... Validation loss: 0.194[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 99.7% ... Training loss: 0.252 ... Validation loss: 0.311[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 99.8% ... Training loss: 0.082 ... Validation loss: 0.174[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 99.8% ... Training loss: 0.087 ... Validation loss: 0.203[[ 0.          0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [-1.33460919 -1.43847501 -1.43847501 ..., -0.19208513 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 1.          1.          1.         ...,  0.          0.          0.        ]]\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651  0.22337816  0.32724398 ...,  0.11951233 -0.19208513\n",
      "  -0.19208513]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "Progress: 99.9% ... Training loss: 0.083 ... Validation loss: 0.212"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "### Set the hyperparameters here ###\n",
    "epochs = 1500\n",
    "learning_rate = 0.3\n",
    "hidden_nodes = 16\n",
    "output_nodes = 3\n",
    "\n",
    "N_i = train_features.shape[1]\n",
    "network = NeuralNetwork(N_i, hidden_nodes, output_nodes, learning_rate)\n",
    "\n",
    "losses = {'train':[], 'validation':[]}\n",
    "for e in range(epochs):\n",
    "    # Go through a random batch of 128 records from the training data set\n",
    "    batch = np.random.choice(train_features.index, size=128)\n",
    "    for record, target in zip(train_features.ix[batch].values, \n",
    "                              train_targets.ix[batch]['cnt']):\n",
    "        network.train(record, target)\n",
    "    \n",
    "    # Printing out the training progress\n",
    "    train_loss = MSE(network.run(train_features), train_targets['cnt'].values)\n",
    "    val_loss = MSE(network.run(val_features), val_targets['cnt'].values)\n",
    "    sys.stdout.write(\"\\rProgress: \" + str(100 * e/float(epochs))[:4] \\\n",
    "                     + \"% ... Training loss: \" + str(train_loss)[:5] \\\n",
    "                     + \" ... Validation loss: \" + str(val_loss)[:5])\n",
    "    \n",
    "    losses['train'].append(train_loss)\n",
    "    losses['validation'].append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.025828987408265364, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAusAAAH4CAYAAADzU6OVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrIuIiIiIBJSSdRERERGRgPp/GIDz5mGpx7wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a67abe5860>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 252,
       "width": 373
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses['train'], label='Training loss')\n",
    "plt.plot(losses['validation'], label='Validation loss')\n",
    "plt.legend()\n",
    "plt.ylim(ymax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check out your predictions\n",
    "\n",
    "Here, use the test data to view how well your network is modeling the data. If something is completely wrong here, make sure each step in your network is implemented correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01564651 -0.19208513 -0.19208513 ..., -1.23074336 -1.23074336\n",
      "  -1.23074336]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+0AAAIgCAYAAADwRojNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEARBiChitAuCIAiCIAiCIAhCRPn/cxxc/h0ZUvsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a67ac6f7f0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 272,
       "width": 502
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "\n",
    "mean, std = scaled_features['cnt']\n",
    "predictions = network.run(test_features)*std + mean\n",
    "ax.plot(predictions[0], label='Prediction')\n",
    "ax.plot((test_targets['cnt']*std + mean).values, label='Data')\n",
    "ax.set_xlim(right=len(predictions))\n",
    "ax.legend()\n",
    "\n",
    "dates = pd.to_datetime(rides.ix[test_data.index]['dteday'])\n",
    "dates = dates.apply(lambda d: d.strftime('%b %d'))\n",
    "ax.set_xticks(np.arange(len(dates))[12::24])\n",
    "_ = ax.set_xticklabels(dates[12::24], rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTIONAL: Thinking about your results(this question will not be evaluated in the rubric).\n",
    " \n",
    "Answer these questions about your results. How well does the model predict the data? Where does it fail? Why does it fail where it does?\n",
    "\n",
    "> R) A maior parte dos erros da previsÃ£o acontecem nos Ãºltimos dias do ano, isso pode ser motivado pelo perÃ­odo de festas, onde menos pessoas utilizam as bicicletas , assim tendo menos dados para aprender.\n",
    "\n",
    "#### Your answer below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit tests\n",
    "\n",
    "Run these unit tests to check the correctness of your network implementation. These tests must all be successful to pass the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "....."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5]\n",
      " [-0.2]\n",
      " [ 0.1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.039s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=5 errors=0 failures=0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "inputs = [0.5, -0.2, 0.1]\n",
    "targets = [0.4]\n",
    "test_w_i_h = np.array([[0.1, 0.4, -0.3], \n",
    "                       [-0.2, 0.5, 0.2]])\n",
    "test_w_h_o = np.array([[0.3, -0.1]])\n",
    "\n",
    "class TestMethods(unittest.TestCase):\n",
    "    \n",
    "    ##########\n",
    "    # Unit tests for data loading\n",
    "    ##########\n",
    "    \n",
    "    def test_data_path(self):\n",
    "        # Test that file path to dataset has been unaltered\n",
    "        self.assertTrue(data_path.lower() == 'bike-sharing-dataset/hour.csv')\n",
    "        \n",
    "    def test_data_loaded(self):\n",
    "        # Test that data frame loaded\n",
    "        self.assertTrue(isinstance(rides, pd.DataFrame))\n",
    "    \n",
    "    ##########\n",
    "    # Unit tests for network functionality\n",
    "    ##########\n",
    "\n",
    "    def test_activation(self):\n",
    "        network = NeuralNetwork(3, 2, 1, 0.5)\n",
    "        # Test that the activation function is a sigmoid\n",
    "        self.assertTrue(np.all(network.activation_function(0.5) == 1/(1+np.exp(-0.5))))\n",
    "\n",
    "    def test_train(self):\n",
    "        # Test that weights are updated correctly on training\n",
    "        network = NeuralNetwork(3, 2, 1, 0.5)\n",
    "        network.weights_input_to_hidden = test_w_i_h.copy()\n",
    "        network.weights_hidden_to_output = test_w_h_o.copy()\n",
    "        \n",
    "        network.train(inputs, targets)\n",
    "        self.assertTrue(np.allclose(network.weights_hidden_to_output, \n",
    "                                    np.array([[ 0.37275328, -0.03172939]])))\n",
    "        self.assertTrue(np.allclose(network.weights_input_to_hidden,\n",
    "                                    np.array([[ 0.10562014,  0.39775194, -0.29887597],\n",
    "                                              [-0.20185996,  0.50074398,  0.19962801]])))\n",
    "\n",
    "    def test_run(self):\n",
    "        # Test correctness of run method\n",
    "        network = NeuralNetwork(3, 2, 1, 0.5)\n",
    "        network.weights_input_to_hidden = test_w_i_h.copy()\n",
    "        network.weights_hidden_to_output = test_w_h_o.copy()\n",
    "\n",
    "        self.assertTrue(np.allclose(network.run(inputs), 0.09998924))\n",
    "\n",
    "suite = unittest.TestLoader().loadTestsFromModule(TestMethods())\n",
    "unittest.TextTestRunner().run(suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
